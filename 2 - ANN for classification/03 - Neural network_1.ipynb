{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeartDisease    BMI  Smoking  AlcoholDrinking  Stroke  PhysicalHealth  \\\n",
       "0             0  20.34        0                0       1               0   \n",
       "1             0  24.21        0                0       0               0   \n",
       "2             0  31.64        1                0       0               5   \n",
       "3             0  28.37        1                0       0               0   \n",
       "4             0  28.15        0                0       0               7   \n",
       "\n",
       "   MentalHealth  DiffWalking  Sex  AgeCategory  Race  Diabetic  \\\n",
       "0             0            0    0           80     0         0   \n",
       "1             0            0    0           77     0         0   \n",
       "2             0            1    0           80     0         2   \n",
       "3             0            1    1           77     0         2   \n",
       "4             0            1    0           80     0         0   \n",
       "\n",
       "   PhysicalActivity  GenHealth  SleepTime  Asthma  KidneyDisease  SkinCancer  \n",
       "0                 1          3          7       0              0           0  \n",
       "1                 0          2          6       0              0           1  \n",
       "2                 0          2          9       1              0           0  \n",
       "3                 1          3          8       0              0           0  \n",
       "4                 0          2          7       0              0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload data\n",
    "df = pd.read_csv(\"balanced_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartDisease        0\n",
       "BMI                 0\n",
       "Smoking             0\n",
       "AlcoholDrinking     0\n",
       "Stroke              0\n",
       "PhysicalHealth      0\n",
       "MentalHealth        0\n",
       "DiffWalking         0\n",
       "Sex                 0\n",
       "AgeCategory         0\n",
       "Race                0\n",
       "Diabetic            0\n",
       "PhysicalActivity    0\n",
       "GenHealth           0\n",
       "SleepTime           0\n",
       "Asthma              0\n",
       "KidneyDisease       0\n",
       "SkinCancer          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# common quick check, do we have missing values, and if so\n",
    "# in which variables\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeartDisease        1.00\n",
       "AgeCategory         0.23\n",
       "Stroke              0.15\n",
       "Diabetic            0.13\n",
       "DiffWalking         0.13\n",
       "KidneyDisease       0.11\n",
       "Smoking             0.09\n",
       "SkinCancer          0.09\n",
       "Sex                 0.09\n",
       "PhysicalHealth      0.06\n",
       "BMI                 0.04\n",
       "SleepTime           0.03\n",
       "Asthma              0.01\n",
       "AlcoholDrinking    -0.03\n",
       "Race               -0.05\n",
       "PhysicalActivity   -0.05\n",
       "MentalHealth       -0.05\n",
       "GenHealth          -0.19\n",
       "Name: HeartDisease, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Let's compare the variables, can we drop something?\n",
    "\n",
    "# remember: any variable that doesn't bring anything to the table\n",
    "# is essentially just noise for the machine learning model\n",
    "corr_matrix = df.corr()['HeartDisease']\n",
    "corr_matrix.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " # by inspecting correlation matrix and SelectKBest results\n",
    "# we decided to drop these variables, since they don't really bring anything into the result\n",
    "# thus resulting in extra noise in the dataset\n",
    "removables = [\"GenHealth\", \"MentalHealth\", \"PhysicalActivity\", \"Race\", \"AlcoholDrinking\", \"Asthma\", \"SleepTime\"]\n",
    "df = df.drop(removables, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "df['HeartDisease'] = df['HeartDisease'].replace({0: \"No\", 1: \"Yes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>24.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>31.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>28.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>28.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HeartDisease   BMI  Smoking  Stroke  PhysicalHealth  DiffWalking  Sex  \\\n",
       "0           No 20.34        0       1               0            0    0   \n",
       "1           No 24.21        0       0               0            0    0   \n",
       "2           No 31.64        1       0               5            1    0   \n",
       "3           No 28.37        1       0               0            1    1   \n",
       "4           No 28.15        0       0               7            1    0   \n",
       "\n",
       "   AgeCategory  Diabetic  KidneyDisease  SkinCancer  \n",
       "0           80         0              0           0  \n",
       "1           77         0              0           1  \n",
       "2           80         2              0           0  \n",
       "3           77         2              0           0  \n",
       "4           80         0              0           0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No', 'Yes']\n"
     ]
    }
   ],
   "source": [
    "# save the categories into a list\n",
    "categories = list(np.unique(df['HeartDisease']))\n",
    "print(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  X/y train/test/validation -split\n",
    "\n",
    "# everything else except the target variable\n",
    "X = df.drop(\"HeartDisease\", axis=1)\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "y_temp = df['HeartDisease']\n",
    "\n",
    "# since we are doing classification, we have to process our target values with an encoder\n",
    "# and convert them into a categorical TensorFlow/Keras -format \n",
    "le = LabelEncoder()\n",
    "y_enc = le.fit_transform(y_temp)\n",
    "\n",
    "# Converting the label into a matrix form\n",
    "y = tf.keras.utils.to_categorical(y_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AgeCategory</td>\n",
       "      <td>59552.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Diabetic</td>\n",
       "      <td>6199.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stroke</td>\n",
       "      <td>4583.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DiffWalking</td>\n",
       "      <td>3256.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PhysicalHealth</td>\n",
       "      <td>3143.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KidneyDisease</td>\n",
       "      <td>2281.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SkinCancer</td>\n",
       "      <td>1435.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smoking</td>\n",
       "      <td>1067.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sex</td>\n",
       "      <td>737.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BMI</td>\n",
       "      <td>335.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features    Score\n",
       "6     AgeCategory 59552.11\n",
       "7        Diabetic  6199.46\n",
       "2          Stroke  4583.15\n",
       "4     DiffWalking  3256.44\n",
       "3  PhysicalHealth  3143.94\n",
       "8   KidneyDisease  2281.46\n",
       "9      SkinCancer  1435.77\n",
       "1         Smoking  1067.90\n",
       "5             Sex   737.30\n",
       "0             BMI   335.71"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# convert all continuous variables to integer,\n",
    "# and convert all negative numbers to 0\n",
    "X_cat = X.astype(int)\n",
    "X_cat = X_cat.clip(lower=0)\n",
    "\n",
    "# initialize chi2 and SelectKBest\n",
    "# Note: chi2 -test is a very common test\n",
    "# in statistics and quantitative analysis\n",
    "# basically it studies the data whether variables are related\n",
    "# or independent of each other\n",
    "chi_2_features = SelectKBest(chi2, k=len(X_cat.columns))\n",
    "\n",
    "# fit our data to the SelectKBest\n",
    "best_features = chi_2_features.fit(X_cat,y.astype(int))\n",
    "\n",
    "# use decimal format in table print later\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# wrap it up, and show the results\n",
    "# the higher the score, the more effect that column has on target variable\n",
    "df_features = pd.DataFrame(best_features.scores_)\n",
    "df_columns = pd.DataFrame(X_cat.columns)\n",
    "f_scores = pd.concat([df_columns,df_features],axis=1)\n",
    "f_scores.columns = ['Features','Score']\n",
    "f_scores.sort_values(by='Score',ascending=False)\n",
    "\n",
    "# AgeCategory, Diabetic, Stroke\n",
    "# have the most impact on the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e1003118\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:142: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │            \u001b[38;5;34m40\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m18\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">370</span> (1.45 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m370\u001b[0m (1.45 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">350</span> (1.37 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m350\u001b[0m (1.37 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20</span> (80.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m20\u001b[0m (80.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Create neural network model\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(len(X.columns),)),\n",
    "        layers.Dense(16, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(l1=0.1)),\n",
    "        layers.Dense(8, activation=\"relu\"),\n",
    "        layers.Dense(len(categories), activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# compile the model, this time we use categorical crossentropy for loss -function\n",
    "# and we also measure the accuracy of our model in the metrics\n",
    "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.8801 - val_accuracy: 0.9258 - val_loss: 0.2682\n",
      "Epoch 2/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2539 - val_accuracy: 0.9258 - val_loss: 0.2331\n",
      "Epoch 3/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2313 - val_accuracy: 0.9258 - val_loss: 0.2323\n",
      "Epoch 4/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2339 - val_accuracy: 0.9258 - val_loss: 0.2300\n",
      "Epoch 5/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2323 - val_accuracy: 0.9258 - val_loss: 0.2295\n",
      "Epoch 6/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.2295 - val_accuracy: 0.9258 - val_loss: 0.2332\n",
      "Epoch 7/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2292\n",
      "Epoch 8/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2292 - val_accuracy: 0.9258 - val_loss: 0.2299\n",
      "Epoch 9/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2279\n",
      "Epoch 10/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2271\n",
      "Epoch 11/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2298\n",
      "Epoch 12/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2289 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 13/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2298 - val_accuracy: 0.9258 - val_loss: 0.2254\n",
      "Epoch 14/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2313 - val_accuracy: 0.9258 - val_loss: 0.2255\n",
      "Epoch 15/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2298 - val_accuracy: 0.9258 - val_loss: 0.2299\n",
      "Epoch 16/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2302 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 17/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 18/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2272 - val_accuracy: 0.9258 - val_loss: 0.2255\n",
      "Epoch 19/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2287 - val_accuracy: 0.9258 - val_loss: 0.2292\n",
      "Epoch 20/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 948us/step - accuracy: 0.9270 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2260\n",
      "Epoch 21/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2273\n",
      "Epoch 22/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.2324 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 23/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2291 - val_accuracy: 0.9258 - val_loss: 0.2290\n",
      "Epoch 24/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2289 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 25/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2313 - val_accuracy: 0.9258 - val_loss: 0.2300\n",
      "Epoch 26/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2304\n",
      "Epoch 27/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2289 - val_accuracy: 0.9258 - val_loss: 0.2287\n",
      "Epoch 28/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2299 - val_accuracy: 0.9258 - val_loss: 0.2308\n",
      "Epoch 29/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2300\n",
      "Epoch 30/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2246\n",
      "Epoch 31/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2259\n",
      "Epoch 32/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2254\n",
      "Epoch 33/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9278 - loss: 0.2249 - val_accuracy: 0.9258 - val_loss: 0.2272\n",
      "Epoch 34/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2300 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 35/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2261 - val_accuracy: 0.9258 - val_loss: 0.2257\n",
      "Epoch 36/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2292 - val_accuracy: 0.9258 - val_loss: 0.2269\n",
      "Epoch 37/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2273 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 38/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9288 - loss: 0.2228 - val_accuracy: 0.9258 - val_loss: 0.2273\n",
      "Epoch 39/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2299 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 40/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2263 - val_accuracy: 0.9258 - val_loss: 0.2274\n",
      "Epoch 41/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2282 - val_accuracy: 0.9258 - val_loss: 0.2278\n",
      "Epoch 42/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2306 - val_accuracy: 0.9258 - val_loss: 0.2263\n",
      "Epoch 43/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 44/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2305 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 45/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 46/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2290\n",
      "Epoch 47/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2269\n",
      "Epoch 48/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2246\n",
      "Epoch 49/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2283 - val_accuracy: 0.9258 - val_loss: 0.2277\n",
      "Epoch 50/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2256 - val_accuracy: 0.9258 - val_loss: 0.2322\n",
      "Epoch 51/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2297 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 52/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2294 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 53/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2288\n",
      "Epoch 54/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 55/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2288\n",
      "Epoch 56/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2269\n",
      "Epoch 57/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2255\n",
      "Epoch 58/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2265 - val_accuracy: 0.9258 - val_loss: 0.2263\n",
      "Epoch 59/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2246\n",
      "Epoch 60/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2280 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 61/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2282\n",
      "Epoch 62/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2260\n",
      "Epoch 63/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2264 - val_accuracy: 0.9258 - val_loss: 0.2273\n",
      "Epoch 64/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2284\n",
      "Epoch 65/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2268\n",
      "Epoch 66/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 67/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2280 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 68/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2294 - val_accuracy: 0.9258 - val_loss: 0.2248\n",
      "Epoch 69/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2263 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 70/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 71/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 978us/step - accuracy: 0.9267 - loss: 0.2273 - val_accuracy: 0.9258 - val_loss: 0.2289\n",
      "Epoch 72/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 978us/step - accuracy: 0.9271 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2263\n",
      "Epoch 73/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2283\n",
      "Epoch 74/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 75/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2256 - val_accuracy: 0.9258 - val_loss: 0.2272\n",
      "Epoch 76/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 995us/step - accuracy: 0.9264 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 77/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 966us/step - accuracy: 0.9285 - loss: 0.2238 - val_accuracy: 0.9258 - val_loss: 0.2238\n",
      "Epoch 78/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 958us/step - accuracy: 0.9278 - loss: 0.2252 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 79/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 926us/step - accuracy: 0.9273 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2279\n",
      "Epoch 80/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 971us/step - accuracy: 0.9256 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 81/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 82/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2240\n",
      "Epoch 83/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2271\n",
      "Epoch 84/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 85/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 86/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2257 - val_accuracy: 0.9258 - val_loss: 0.2288\n",
      "Epoch 87/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2257 - val_accuracy: 0.9258 - val_loss: 0.2257\n",
      "Epoch 88/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 89/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 90/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 91/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2261 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 92/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2241\n",
      "Epoch 93/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2272\n",
      "Epoch 94/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 95/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 96/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.2299 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 97/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2301 - val_accuracy: 0.9258 - val_loss: 0.2301\n",
      "Epoch 98/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2288\n",
      "Epoch 99/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2297 - val_accuracy: 0.9258 - val_loss: 0.2280\n",
      "Epoch 100/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2251\n",
      "Epoch 101/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2309 - val_accuracy: 0.9258 - val_loss: 0.2274\n",
      "Epoch 102/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 103/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 104/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2257 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 105/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2267 - val_accuracy: 0.9258 - val_loss: 0.2257\n",
      "Epoch 106/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 107/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 108/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 109/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.2251 - val_accuracy: 0.9258 - val_loss: 0.2248\n",
      "Epoch 110/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2259\n",
      "Epoch 111/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2299 - val_accuracy: 0.9258 - val_loss: 0.2278\n",
      "Epoch 112/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2300 - val_accuracy: 0.9258 - val_loss: 0.2289\n",
      "Epoch 113/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2256 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 114/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2295 - val_accuracy: 0.9258 - val_loss: 0.2279\n",
      "Epoch 115/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 974us/step - accuracy: 0.9266 - loss: 0.2277 - val_accuracy: 0.9258 - val_loss: 0.2242\n",
      "Epoch 116/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2291 - val_accuracy: 0.9258 - val_loss: 0.2251\n",
      "Epoch 117/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 118/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2264 - val_accuracy: 0.9258 - val_loss: 0.2240\n",
      "Epoch 119/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 120/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2262 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 121/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 122/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 123/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 124/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2268\n",
      "Epoch 125/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2262 - val_accuracy: 0.9258 - val_loss: 0.2297\n",
      "Epoch 126/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2254\n",
      "Epoch 127/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 128/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2265 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 129/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2263 - val_accuracy: 0.9258 - val_loss: 0.2278\n",
      "Epoch 130/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.2301 - val_accuracy: 0.9258 - val_loss: 0.2240\n",
      "Epoch 131/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2256 - val_accuracy: 0.9258 - val_loss: 0.2257\n",
      "Epoch 132/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2253 - val_accuracy: 0.9258 - val_loss: 0.2319\n",
      "Epoch 133/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.2313 - val_accuracy: 0.9258 - val_loss: 0.2243\n",
      "Epoch 134/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2261 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 135/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2308 - val_accuracy: 0.9258 - val_loss: 0.2263\n",
      "Epoch 136/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2310 - val_accuracy: 0.9258 - val_loss: 0.2288\n",
      "Epoch 137/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2298 - val_accuracy: 0.9258 - val_loss: 0.2321\n",
      "Epoch 138/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 139/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2292 - val_accuracy: 0.9258 - val_loss: 0.2255\n",
      "Epoch 140/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2277 - val_accuracy: 0.9258 - val_loss: 0.2274\n",
      "Epoch 141/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2293 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 142/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 143/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2241\n",
      "Epoch 144/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2241\n",
      "Epoch 145/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 146/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2274\n",
      "Epoch 147/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 148/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2289 - val_accuracy: 0.9258 - val_loss: 0.2251\n",
      "Epoch 149/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2305 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 150/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2262 - val_accuracy: 0.9258 - val_loss: 0.2276\n",
      "Epoch 151/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2248\n",
      "Epoch 152/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2246\n",
      "Epoch 153/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2273 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 154/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.2258 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 155/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2272\n",
      "Epoch 156/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2261 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 157/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2282 - val_accuracy: 0.9258 - val_loss: 0.2273\n",
      "Epoch 158/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2268 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 159/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2253 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 160/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 161/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 162/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2283 - val_accuracy: 0.9258 - val_loss: 0.2279\n",
      "Epoch 163/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2292\n",
      "Epoch 164/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2295 - val_accuracy: 0.9258 - val_loss: 0.2286\n",
      "Epoch 165/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2245\n",
      "Epoch 166/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2304\n",
      "Epoch 167/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2265 - val_accuracy: 0.9258 - val_loss: 0.2240\n",
      "Epoch 168/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2283 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 169/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2235\n",
      "Epoch 170/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2254\n",
      "Epoch 171/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2280 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 172/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2261 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 173/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2240\n",
      "Epoch 174/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2254 - val_accuracy: 0.9258 - val_loss: 0.2227\n",
      "Epoch 175/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2302 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 176/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2282 - val_accuracy: 0.9258 - val_loss: 0.2277\n",
      "Epoch 177/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 178/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 179/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2268\n",
      "Epoch 180/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 181/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2291\n",
      "Epoch 182/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 183/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 184/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 185/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2241\n",
      "Epoch 186/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9284 - loss: 0.2243 - val_accuracy: 0.9258 - val_loss: 0.2299\n",
      "Epoch 187/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2294 - val_accuracy: 0.9258 - val_loss: 0.2260\n",
      "Epoch 188/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2295 - val_accuracy: 0.9258 - val_loss: 0.2251\n",
      "Epoch 189/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 190/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2301 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 191/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2303 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 192/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2293 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 193/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2292\n",
      "Epoch 194/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 195/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2290\n",
      "Epoch 196/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2315 - val_accuracy: 0.9258 - val_loss: 0.2238\n",
      "Epoch 197/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 198/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 199/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 200/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2242\n",
      "Epoch 201/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2276\n",
      "Epoch 202/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2267 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 203/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 204/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2303 - val_accuracy: 0.9258 - val_loss: 0.2320\n",
      "Epoch 205/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2238 - val_accuracy: 0.9258 - val_loss: 0.2284\n",
      "Epoch 206/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.2292 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 207/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.2298 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 208/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2254 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 209/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.2295 - val_accuracy: 0.9258 - val_loss: 0.2257\n",
      "Epoch 210/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2260\n",
      "Epoch 211/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.2308 - val_accuracy: 0.9258 - val_loss: 0.2273\n",
      "Epoch 212/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 213/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.2305 - val_accuracy: 0.9258 - val_loss: 0.2325\n",
      "Epoch 214/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 215/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 216/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.2305 - val_accuracy: 0.9258 - val_loss: 0.2240\n",
      "Epoch 217/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2265 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 218/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2265 - val_accuracy: 0.9258 - val_loss: 0.2246\n",
      "Epoch 219/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2292 - val_accuracy: 0.9258 - val_loss: 0.2268\n",
      "Epoch 220/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2248\n",
      "Epoch 221/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9253 - loss: 0.2293 - val_accuracy: 0.9258 - val_loss: 0.2268\n",
      "Epoch 222/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2300 - val_accuracy: 0.9258 - val_loss: 0.2269\n",
      "Epoch 223/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2262 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 224/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.2280 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 225/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2309\n",
      "Epoch 226/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2260\n",
      "Epoch 227/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2263\n",
      "Epoch 228/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2303 - val_accuracy: 0.9258 - val_loss: 0.2297\n",
      "Epoch 229/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2282\n",
      "Epoch 230/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2289 - val_accuracy: 0.9258 - val_loss: 0.2251\n",
      "Epoch 231/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2272 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 232/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2258 - val_accuracy: 0.9258 - val_loss: 0.2260\n",
      "Epoch 233/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9280 - loss: 0.2257 - val_accuracy: 0.9258 - val_loss: 0.2283\n",
      "Epoch 234/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.2258 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 235/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 236/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2239 - val_accuracy: 0.9258 - val_loss: 0.2259\n",
      "Epoch 237/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2249 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 238/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2293 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 239/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 240/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2267\n",
      "Epoch 241/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2273 - val_accuracy: 0.9258 - val_loss: 0.2240\n",
      "Epoch 242/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2302 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 243/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2269\n",
      "Epoch 244/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2280 - val_accuracy: 0.9258 - val_loss: 0.2280\n",
      "Epoch 245/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 246/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2273 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 247/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2236\n",
      "Epoch 248/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2289\n",
      "Epoch 249/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2241\n",
      "Epoch 250/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2291 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 251/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2292 - val_accuracy: 0.9258 - val_loss: 0.2298\n",
      "Epoch 252/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2273 - val_accuracy: 0.9258 - val_loss: 0.2233\n",
      "Epoch 253/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2234\n",
      "Epoch 254/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 255/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 256/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2262 - val_accuracy: 0.9258 - val_loss: 0.2278\n",
      "Epoch 257/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.2264 - val_accuracy: 0.9258 - val_loss: 0.2242\n",
      "Epoch 258/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 259/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.2311 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 260/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2246\n",
      "Epoch 261/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2268\n",
      "Epoch 262/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2289\n",
      "Epoch 263/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.2277 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 264/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.2280 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 265/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2287\n",
      "Epoch 266/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2277 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 267/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 268/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 269/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2260 - val_accuracy: 0.9258 - val_loss: 0.2254\n",
      "Epoch 270/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2261 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 271/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2267 - val_accuracy: 0.9258 - val_loss: 0.2287\n",
      "Epoch 272/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 273/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2289 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 274/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2302 - val_accuracy: 0.9258 - val_loss: 0.2247\n",
      "Epoch 275/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2245\n",
      "Epoch 276/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2272 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 277/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 278/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2273 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 279/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2254\n",
      "Epoch 280/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2268 - val_accuracy: 0.9258 - val_loss: 0.2279\n",
      "Epoch 281/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2301\n",
      "Epoch 282/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 283/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2243\n",
      "Epoch 284/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2283\n",
      "Epoch 285/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2285 - val_accuracy: 0.9258 - val_loss: 0.2268\n",
      "Epoch 286/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2280\n",
      "Epoch 287/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.2256 - val_accuracy: 0.9258 - val_loss: 0.2271\n",
      "Epoch 288/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2273\n",
      "Epoch 289/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2276\n",
      "Epoch 290/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2269\n",
      "Epoch 291/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.2280 - val_accuracy: 0.9258 - val_loss: 0.2235\n",
      "Epoch 292/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2272 - val_accuracy: 0.9258 - val_loss: 0.2269\n",
      "Epoch 293/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2270\n",
      "Epoch 294/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2299 - val_accuracy: 0.9258 - val_loss: 0.2246\n",
      "Epoch 295/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2277 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 296/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.2262 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 297/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2263\n",
      "Epoch 298/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2275\n",
      "Epoch 299/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9277 - loss: 0.2256 - val_accuracy: 0.9258 - val_loss: 0.2251\n",
      "Epoch 300/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2295 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 301/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2283\n",
      "Epoch 302/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2297 - val_accuracy: 0.9258 - val_loss: 0.2259\n",
      "Epoch 303/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2267 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 304/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2269 - val_accuracy: 0.9258 - val_loss: 0.2251\n",
      "Epoch 305/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 306/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2305\n",
      "Epoch 307/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2248\n",
      "Epoch 308/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.2293 - val_accuracy: 0.9258 - val_loss: 0.2238\n",
      "Epoch 309/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2255\n",
      "Epoch 310/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.2284 - val_accuracy: 0.9258 - val_loss: 0.2245\n",
      "Epoch 311/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.2306 - val_accuracy: 0.9258 - val_loss: 0.2298\n",
      "Epoch 312/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2268 - val_accuracy: 0.9258 - val_loss: 0.2281\n",
      "Epoch 313/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2245\n",
      "Epoch 314/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2277 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 315/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2281\n",
      "Epoch 316/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2254 - val_accuracy: 0.9258 - val_loss: 0.2253\n",
      "Epoch 317/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.2294 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 318/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.2290 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 319/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2268 - val_accuracy: 0.9258 - val_loss: 0.2252\n",
      "Epoch 320/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2281\n",
      "Epoch 321/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.2291 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 322/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2261\n",
      "Epoch 323/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 324/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.2289 - val_accuracy: 0.9258 - val_loss: 0.2256\n",
      "Epoch 325/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.2260 - val_accuracy: 0.9258 - val_loss: 0.2255\n",
      "Epoch 326/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2245\n",
      "Epoch 327/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2278 - val_accuracy: 0.9258 - val_loss: 0.2235\n",
      "Epoch 328/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.2266 - val_accuracy: 0.9258 - val_loss: 0.2271\n",
      "Epoch 329/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2270 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 330/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2288 - val_accuracy: 0.9258 - val_loss: 0.2250\n",
      "Epoch 331/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2251 - val_accuracy: 0.9258 - val_loss: 0.2238\n",
      "Epoch 332/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.2263 - val_accuracy: 0.9258 - val_loss: 0.2248\n",
      "Epoch 333/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2264\n",
      "Epoch 334/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.2277 - val_accuracy: 0.9258 - val_loss: 0.2244\n",
      "Epoch 335/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2239\n",
      "Epoch 336/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2271 - val_accuracy: 0.9258 - val_loss: 0.2262\n",
      "Epoch 337/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.2253 - val_accuracy: 0.9258 - val_loss: 0.2239\n",
      "Epoch 338/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2263 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 339/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2258 - val_accuracy: 0.9258 - val_loss: 0.2304\n",
      "Epoch 340/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.2296 - val_accuracy: 0.9258 - val_loss: 0.2266\n",
      "Epoch 341/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.2267 - val_accuracy: 0.9258 - val_loss: 0.2259\n",
      "Epoch 342/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.2281 - val_accuracy: 0.9258 - val_loss: 0.2241\n",
      "Epoch 343/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2241\n",
      "Epoch 344/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2252 - val_accuracy: 0.9258 - val_loss: 0.2248\n",
      "Epoch 345/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2252 - val_accuracy: 0.9258 - val_loss: 0.2249\n",
      "Epoch 346/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2260 - val_accuracy: 0.9258 - val_loss: 0.2289\n",
      "Epoch 347/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2260 - val_accuracy: 0.9258 - val_loss: 0.2239\n",
      "Epoch 348/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9253 - loss: 0.2303 - val_accuracy: 0.9258 - val_loss: 0.2267\n",
      "Epoch 349/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2239\n",
      "Epoch 350/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9247 - loss: 0.2308 - val_accuracy: 0.9258 - val_loss: 0.2257\n",
      "Epoch 351/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2267 - val_accuracy: 0.9258 - val_loss: 0.2286\n",
      "Epoch 352/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9283 - loss: 0.2243 - val_accuracy: 0.9258 - val_loss: 0.2272\n",
      "Epoch 353/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.2253 - val_accuracy: 0.9258 - val_loss: 0.2258\n",
      "Epoch 354/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2274 - val_accuracy: 0.9258 - val_loss: 0.2260\n",
      "Epoch 355/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.2279 - val_accuracy: 0.9258 - val_loss: 0.2274\n",
      "Epoch 356/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.2304 - val_accuracy: 0.9258 - val_loss: 0.2273\n",
      "Epoch 357/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.2276 - val_accuracy: 0.9258 - val_loss: 0.2277\n",
      "Epoch 358/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.2287 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 359/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.2286 - val_accuracy: 0.9258 - val_loss: 0.2284\n",
      "Epoch 360/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.2275 - val_accuracy: 0.9258 - val_loss: 0.2265\n",
      "Epoch 361/400\n",
      "\u001b[1m 872/4366\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9248 - loss: 0.2268"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(x=X_train, y=y_train, epochs=400, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df[['loss', 'val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the final model loss/accuracy/evaluation values\n",
    "# the values should again match mostly\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get predictions and convert with argmax() to get categories \n",
    "# instead of raw probabilities\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# convert also y-test -values with argmax\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, test_predictions), xticklabels=categories, yticklabels=categories, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the classification report based on true values and predictions\n",
    "print(classification_report(y_test, test_predictions, target_names=categories))\n",
    "\n",
    "# get overall accuracy of the model and print it\n",
    "acc = accuracy_score(y_test, test_predictions)\n",
    "print(\"\\nModel overall accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In multi category classification , AUC values are often interpreted as follows: \n",
    "# 0.5-0.6 (failed)\n",
    "# 0.6-0.7 (worthless)\n",
    "# 0.7-0.8 (poor)\n",
    "# 0.8-0.9 (good)\n",
    "# > 0.9 (excellent)\n",
    "\n",
    "# get ROC-AUC -score\n",
    "roc_auc_score(y, model.predict(X), multi_class=\"ovr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with some new imaginary data\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'battery_power': 800, \n",
    "    'fc': 12, \n",
    "    'int_memory': 2,  \n",
    "    'mobile_wt': 300, \n",
    "    'n_cores': 4, \n",
    "    'pc': 36,\n",
    "    'px_width': 1890,\n",
    "    'px_height': 1222, \n",
    "    'ram': 8096,\n",
    "    'sc_h': 13, \n",
    "    'sc_w': 4, \n",
    "    'talk_time': 19\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])\n",
    "result = model.predict(tester_row)[0]\n",
    "result_text = categories[np.argmax(result)]\n",
    "\n",
    "# 0 cheapest, 3 most expensive\n",
    "print(\"-> 0 cheapest, 3 most expensive category\")\n",
    "print(f\"Predicted price range: {result_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

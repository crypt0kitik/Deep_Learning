{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeartDisease    BMI  Smoking  AlcoholDrinking  Stroke  PhysicalHealth  \\\n",
       "0             0  20.34        0                0       1               0   \n",
       "1             0  24.21        0                0       0               0   \n",
       "2             0  31.64        1                0       0               5   \n",
       "3             0  28.37        1                0       0               0   \n",
       "4             0  28.15        0                0       0               7   \n",
       "\n",
       "   MentalHealth  DiffWalking  Sex  AgeCategory  Race  Diabetic  \\\n",
       "0             0            0    0           80     0         0   \n",
       "1             0            0    0           77     0         0   \n",
       "2             0            1    0           80     0         2   \n",
       "3             0            1    1           77     0         2   \n",
       "4             0            1    0           80     0         0   \n",
       "\n",
       "   PhysicalActivity  GenHealth  SleepTime  Asthma  KidneyDisease  SkinCancer  \n",
       "0                 1          3          7       0              0           0  \n",
       "1                 0          2          6       0              0           1  \n",
       "2                 0          2          9       1              0           0  \n",
       "3                 1          3          8       0              0           0  \n",
       "4                 0          2          7       0              0           0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload data\n",
    "df = pd.read_csv(\"balanced_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HeartDisease', 'BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
       "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
       "       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
       "       'Asthma', 'KidneyDisease', 'SkinCancer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the column names for easier copying for X/y\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  X/y -variables\n",
    "\n",
    "# if you  have more than one independent variables, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "# in this case, everything else except the amount_paid\n",
    "X = df[['BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
    "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
    "       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
    "       'Asthma', 'KidneyDisease', 'SkinCancer']]\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "# in this case, amount_paid => how big is the electricity bill\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train/test/validation -split\n",
    "\n",
    "# unfortunately the scikit-learn's train_test_split doesn't support validation\n",
    "# set split in itself.\n",
    "# if you want to split the test set into two for a validation set too, try this trick:\n",
    "\n",
    "# first, train/test split => 70% for training, 30% for other purposes (temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# now, split the 30% for other purposes by 50% (resulting in 2 x 15%)\n",
    "# so finally, we have:\n",
    "# 70% for training\n",
    "# 15% for testing\n",
    "# 15% for validation\n",
    "# => 70 + 15 +15 = 100%\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data amount: 139688\n",
      "Test data amount: 29934\n",
      "Validation data amount: 29933\n"
     ]
    }
   ],
   "source": [
    "# just seeing how much data we have in each\n",
    "print(f\"Train data amount: {len(X_train)}\")\n",
    "print(f\"Test data amount: {len(X_test)}\")\n",
    "print(f\"Validation data amount: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e1003118\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m126\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,928</span> (19.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,928\u001b[0m (19.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,928</span> (19.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,928\u001b[0m (19.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Create neural network structure\n",
    "variable_amount = len(X.columns)\n",
    "\n",
    "# Define Sequential neural network model\n",
    "# I have 18 columns --> 18 - 1 = 17 input layers\n",
    "# I have 2 options for output (Yes or No for Heart disease)\n",
    "# --> 2 output layers\n",
    "\n",
    "# CHANGED LAYERS:\n",
    "model_1 = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(7, activation=\"relu\", input_shape=(variable_amount,)),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(2)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# CNAHGED optimizer from adam to rmsprop\n",
    "model_1.compile(optimizer='rmsprop', loss='mse')\n",
    "\n",
    "# print out the summary of your model\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.1881 - val_loss: 0.0627\n",
      "Epoch 2/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0613 - val_loss: 0.0601\n",
      "Epoch 3/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0606 - val_loss: 0.0610\n",
      "Epoch 4/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0602 - val_loss: 0.0608\n",
      "Epoch 5/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0596 - val_loss: 0.0600\n",
      "Epoch 6/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0603\n",
      "Epoch 7/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0599 - val_loss: 0.0607\n",
      "Epoch 8/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0606 - val_loss: 0.0621\n",
      "Epoch 9/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0596 - val_loss: 0.0600\n",
      "Epoch 10/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0601 - val_loss: 0.0597\n",
      "Epoch 11/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0600\n",
      "Epoch 12/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0624\n",
      "Epoch 13/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0593 - val_loss: 0.0602\n",
      "Epoch 14/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 15/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0601 - val_loss: 0.0597\n",
      "Epoch 16/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0612 - val_loss: 0.0596\n",
      "Epoch 17/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0602 - val_loss: 0.0598\n",
      "Epoch 18/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0590 - val_loss: 0.0601\n",
      "Epoch 19/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0608\n",
      "Epoch 20/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 21/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0604\n",
      "Epoch 22/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0599\n",
      "Epoch 23/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0592 - val_loss: 0.0616\n",
      "Epoch 24/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0596 - val_loss: 0.0615\n",
      "Epoch 25/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0604\n",
      "Epoch 26/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0598\n",
      "Epoch 27/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0599\n",
      "Epoch 28/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0601 - val_loss: 0.0607\n",
      "Epoch 29/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0602 - val_loss: 0.0609\n",
      "Epoch 30/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0599\n",
      "Epoch 31/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0590 - val_loss: 0.0600\n",
      "Epoch 32/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0598 - val_loss: 0.0601\n",
      "Epoch 33/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0598 - val_loss: 0.0604\n",
      "Epoch 34/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0599\n",
      "Epoch 35/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0607 - val_loss: 0.0598\n",
      "Epoch 36/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0606 - val_loss: 0.0600\n",
      "Epoch 37/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0601\n",
      "Epoch 38/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0607 - val_loss: 0.0595\n",
      "Epoch 39/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0594 - val_loss: 0.0600\n",
      "Epoch 40/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0604 - val_loss: 0.0601\n",
      "Epoch 41/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0609 - val_loss: 0.0607\n",
      "Epoch 42/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0600\n",
      "Epoch 43/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0593 - val_loss: 0.0597\n",
      "Epoch 44/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0607\n",
      "Epoch 45/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0604 - val_loss: 0.0601\n",
      "Epoch 46/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0592 - val_loss: 0.0603\n",
      "Epoch 47/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 48/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 3ms/step - loss: 0.0598 - val_loss: 0.0597\n",
      "Epoch 49/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 50/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0608 - val_loss: 0.0601\n",
      "Epoch 51/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0590 - val_loss: 0.0602\n",
      "Epoch 52/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0608\n",
      "Epoch 53/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0602 - val_loss: 0.0598\n",
      "Epoch 54/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - loss: 0.0605 - val_loss: 0.0606\n",
      "Epoch 55/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0602 - val_loss: 0.0602\n",
      "Epoch 56/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0609 - val_loss: 0.0600\n",
      "Epoch 57/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0605 - val_loss: 0.0599\n",
      "Epoch 58/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 4ms/step - loss: 0.0610 - val_loss: 0.0603\n",
      "Epoch 59/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0609\n",
      "Epoch 60/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0600\n",
      "Epoch 61/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0599\n",
      "Epoch 62/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0605\n",
      "Epoch 63/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.0605\n",
      "Epoch 64/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0599\n",
      "Epoch 65/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0583 - val_loss: 0.0603\n",
      "Epoch 66/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0596 - val_loss: 0.0602\n",
      "Epoch 67/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0598\n",
      "Epoch 68/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0595 - val_loss: 0.0602\n",
      "Epoch 69/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0603\n",
      "Epoch 70/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0594 - val_loss: 0.0601\n",
      "Epoch 71/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0602 - val_loss: 0.0600\n",
      "Epoch 72/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 73/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0595 - val_loss: 0.0598\n",
      "Epoch 74/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0607 - val_loss: 0.0608\n",
      "Epoch 75/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0606 - val_loss: 0.0598\n",
      "Epoch 76/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0602 - val_loss: 0.0597\n",
      "Epoch 77/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0597 - val_loss: 0.0596\n",
      "Epoch 78/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0601 - val_loss: 0.0599\n",
      "Epoch 79/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0609\n",
      "Epoch 80/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0601 - val_loss: 0.0607\n",
      "Epoch 81/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 82/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0598\n",
      "Epoch 83/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 84/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0597\n",
      "Epoch 85/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0598 - val_loss: 0.0602\n",
      "Epoch 86/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0604\n",
      "Epoch 87/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 88/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0597\n",
      "Epoch 89/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0597\n",
      "Epoch 90/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.0602\n",
      "Epoch 91/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0608 - val_loss: 0.0595\n",
      "Epoch 92/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0595\n",
      "Epoch 93/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0606\n",
      "Epoch 94/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0607\n",
      "Epoch 95/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0593 - val_loss: 0.0609\n",
      "Epoch 96/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0595\n",
      "Epoch 97/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0601\n",
      "Epoch 98/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0610 - val_loss: 0.0595\n",
      "Epoch 99/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0597\n",
      "Epoch 100/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0596\n",
      "Epoch 101/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0588 - val_loss: 0.0597\n",
      "Epoch 102/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0605\n",
      "Epoch 103/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0595\n",
      "Epoch 104/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0607\n",
      "Epoch 105/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 0.0589 - val_loss: 0.0603\n",
      "Epoch 106/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0590 - val_loss: 0.0599\n",
      "Epoch 107/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0601\n",
      "Epoch 108/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0589 - val_loss: 0.0598\n",
      "Epoch 109/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0610\n",
      "Epoch 110/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0608\n",
      "Epoch 111/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - loss: 0.0588 - val_loss: 0.0597\n",
      "Epoch 112/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0598\n",
      "Epoch 113/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0601 - val_loss: 0.0609\n",
      "Epoch 114/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0598 - val_loss: 0.0599\n",
      "Epoch 115/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 116/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 117/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0602\n",
      "Epoch 118/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 119/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0599\n",
      "Epoch 120/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.0602\n",
      "Epoch 121/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0595 - val_loss: 0.0597\n",
      "Epoch 122/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0596\n",
      "Epoch 123/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0600\n",
      "Epoch 124/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0595 - val_loss: 0.0595\n",
      "Epoch 125/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.0595\n",
      "Epoch 126/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0608 - val_loss: 0.0602\n",
      "Epoch 127/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0609 - val_loss: 0.0605\n",
      "Epoch 128/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0602 - val_loss: 0.0610\n",
      "Epoch 129/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0600\n",
      "Epoch 130/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0598\n",
      "Epoch 131/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 132/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 133/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 134/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 135/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 136/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0597\n",
      "Epoch 137/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0602 - val_loss: 0.0596\n",
      "Epoch 138/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0605\n",
      "Epoch 139/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0600\n",
      "Epoch 140/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 141/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0600\n",
      "Epoch 142/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0604\n",
      "Epoch 143/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0590 - val_loss: 0.0596\n",
      "Epoch 144/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0601\n",
      "Epoch 145/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0600\n",
      "Epoch 146/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0599\n",
      "Epoch 147/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0604\n",
      "Epoch 148/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.0595\n",
      "Epoch 149/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.0595\n",
      "Epoch 150/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 151/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0603\n",
      "Epoch 152/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0598\n",
      "Epoch 153/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 154/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0589 - val_loss: 0.0596\n",
      "Epoch 155/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0609\n",
      "Epoch 156/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0595\n",
      "Epoch 157/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0599\n",
      "Epoch 158/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0598\n",
      "Epoch 159/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0611 - val_loss: 0.0598\n",
      "Epoch 160/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0609 - val_loss: 0.0595\n",
      "Epoch 161/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0598\n",
      "Epoch 162/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0603\n",
      "Epoch 163/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 164/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 165/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0588 - val_loss: 0.0603\n",
      "Epoch 166/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0603\n",
      "Epoch 167/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0595\n",
      "Epoch 168/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0593 - val_loss: 0.0598\n",
      "Epoch 169/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0598\n",
      "Epoch 170/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0597\n",
      "Epoch 171/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0601\n",
      "Epoch 172/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 173/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0597\n",
      "Epoch 174/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0596 - val_loss: 0.0597\n",
      "Epoch 175/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0599\n",
      "Epoch 176/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0603\n",
      "Epoch 177/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 178/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 179/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0598\n",
      "Epoch 180/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0597\n",
      "Epoch 181/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 182/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0597\n",
      "Epoch 183/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0597\n",
      "Epoch 184/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - loss: 0.0602 - val_loss: 0.0600\n",
      "Epoch 185/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 186/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0593 - val_loss: 0.0600\n",
      "Epoch 187/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0588 - val_loss: 0.0604\n",
      "Epoch 188/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0600\n",
      "Epoch 189/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0601\n",
      "Epoch 190/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0597\n",
      "Epoch 191/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0598\n",
      "Epoch 192/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0587 - val_loss: 0.0598\n",
      "Epoch 193/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0600\n",
      "Epoch 194/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0605 - val_loss: 0.0605\n",
      "Epoch 195/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0606 - val_loss: 0.0600\n",
      "Epoch 196/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0598\n",
      "Epoch 197/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0605\n",
      "Epoch 198/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0617\n",
      "Epoch 199/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0603\n",
      "Epoch 200/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0588 - val_loss: 0.0603\n",
      "Epoch 201/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0600\n",
      "Epoch 202/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0605\n",
      "Epoch 203/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0605\n",
      "Epoch 204/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0601\n",
      "Epoch 205/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0596\n",
      "Epoch 206/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0600\n",
      "Epoch 207/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0602\n",
      "Epoch 208/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0597\n",
      "Epoch 209/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0589 - val_loss: 0.0599\n",
      "Epoch 210/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0596\n",
      "Epoch 211/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0602 - val_loss: 0.0604\n",
      "Epoch 212/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0600\n",
      "Epoch 213/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 214/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.0607\n",
      "Epoch 215/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0603\n",
      "Epoch 216/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0590 - val_loss: 0.0597\n",
      "Epoch 217/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 218/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.0602\n",
      "Epoch 219/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0595\n",
      "Epoch 220/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0596\n",
      "Epoch 221/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0600\n",
      "Epoch 222/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0595\n",
      "Epoch 223/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0611\n",
      "Epoch 224/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0605\n",
      "Epoch 225/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0596 - val_loss: 0.0597\n",
      "Epoch 226/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 227/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0595\n",
      "Epoch 228/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0596\n",
      "Epoch 229/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0589 - val_loss: 0.0611\n",
      "Epoch 230/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0598\n",
      "Epoch 231/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0601\n",
      "Epoch 232/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0603\n",
      "Epoch 233/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.0601\n",
      "Epoch 234/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0599\n",
      "Epoch 235/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 236/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 5ms/step - loss: 0.0602 - val_loss: 0.0601\n",
      "Epoch 237/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0594 - val_loss: 0.0597\n",
      "Epoch 238/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0593 - val_loss: 0.0595\n",
      "Epoch 239/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0595\n",
      "Epoch 240/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - loss: 0.0588 - val_loss: 0.0597\n",
      "Epoch 241/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0599\n",
      "Epoch 242/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0602 - val_loss: 0.0606\n",
      "Epoch 243/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.0595\n",
      "Epoch 244/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 245/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0597 - val_loss: 0.0596\n",
      "Epoch 246/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0594 - val_loss: 0.0595\n",
      "Epoch 247/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0598\n",
      "Epoch 248/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - loss: 0.0604 - val_loss: 0.0596\n",
      "Epoch 249/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.0601\n",
      "Epoch 250/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0594\n",
      "Epoch 251/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0595\n",
      "Epoch 252/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 253/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0597 - val_loss: 0.0599\n",
      "Epoch 254/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0591 - val_loss: 0.0598\n",
      "Epoch 255/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0608 - val_loss: 0.0596\n",
      "Epoch 256/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0597 - val_loss: 0.0597\n",
      "Epoch 257/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - loss: 0.0602 - val_loss: 0.0596\n",
      "Epoch 258/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - loss: 0.0597 - val_loss: 0.0598\n",
      "Epoch 259/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 6ms/step - loss: 0.0592 - val_loss: 0.0597\n",
      "Epoch 260/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 261/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - loss: 0.0591 - val_loss: 0.0614\n",
      "Epoch 262/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.0595\n",
      "Epoch 263/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0595 - val_loss: 0.0595\n",
      "Epoch 264/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0601 - val_loss: 0.0595\n",
      "Epoch 265/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0597\n",
      "Epoch 266/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0595 - val_loss: 0.0597\n",
      "Epoch 267/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0589 - val_loss: 0.0598\n",
      "Epoch 268/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0594 - val_loss: 0.0597\n",
      "Epoch 269/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0594 - val_loss: 0.0597\n",
      "Epoch 270/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 271/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0590 - val_loss: 0.0595\n",
      "Epoch 272/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0598 - val_loss: 0.0602\n",
      "Epoch 273/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0605 - val_loss: 0.0601\n",
      "Epoch 274/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - loss: 0.0598 - val_loss: 0.0597\n",
      "Epoch 275/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - loss: 0.0596 - val_loss: 0.0597\n",
      "Epoch 276/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 277/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 278/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0589 - val_loss: 0.0604\n",
      "Epoch 279/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0595\n",
      "Epoch 280/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0598\n",
      "Epoch 281/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0600 - val_loss: 0.0598\n",
      "Epoch 282/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0596 - val_loss: 0.0595\n",
      "Epoch 283/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0597 - val_loss: 0.0600\n",
      "Epoch 284/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 285/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0592 - val_loss: 0.0597\n",
      "Epoch 286/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0602 - val_loss: 0.0597\n",
      "Epoch 287/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0590 - val_loss: 0.0595\n",
      "Epoch 288/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0589 - val_loss: 0.0598\n",
      "Epoch 289/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - loss: 0.0590 - val_loss: 0.0600\n",
      "Epoch 290/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0598 - val_loss: 0.0599\n",
      "Epoch 291/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - loss: 0.0593 - val_loss: 0.0597\n",
      "Epoch 292/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 293/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.0596\n",
      "Epoch 294/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - loss: 0.0589 - val_loss: 0.0595\n",
      "Epoch 295/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0607 - val_loss: 0.0599\n",
      "Epoch 296/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0600 - val_loss: 0.0597\n",
      "Epoch 297/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0603 - val_loss: 0.0597\n",
      "Epoch 298/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 299/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0594 - val_loss: 0.0598\n",
      "Epoch 300/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 301/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0590 - val_loss: 0.0597\n",
      "Epoch 302/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0597 - val_loss: 0.0599\n",
      "Epoch 303/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0594 - val_loss: 0.0597\n",
      "Epoch 304/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0590 - val_loss: 0.0601\n",
      "Epoch 305/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0604 - val_loss: 0.0600\n",
      "Epoch 306/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0586 - val_loss: 0.0599\n",
      "Epoch 307/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0608 - val_loss: 0.0597\n",
      "Epoch 308/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0591 - val_loss: 0.0596\n",
      "Epoch 309/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0584 - val_loss: 0.0599\n",
      "Epoch 310/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 311/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0590 - val_loss: 0.0596\n",
      "Epoch 312/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - loss: 0.0594 - val_loss: 0.0597\n",
      "Epoch 313/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0588 - val_loss: 0.0598\n",
      "Epoch 314/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0596 - val_loss: 0.0595\n",
      "Epoch 315/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 316/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0595 - val_loss: 0.0595\n",
      "Epoch 317/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0598 - val_loss: 0.0599\n",
      "Epoch 318/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0592 - val_loss: 0.0597\n",
      "Epoch 319/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0596\n",
      "Epoch 320/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 321/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0588 - val_loss: 0.0596\n",
      "Epoch 322/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0589 - val_loss: 0.0596\n",
      "Epoch 323/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0593 - val_loss: 0.0598\n",
      "Epoch 324/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1ms/step - loss: 0.0595 - val_loss: 0.0599\n",
      "Epoch 325/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0593 - val_loss: 0.0598\n",
      "Epoch 326/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0595 - val_loss: 0.0595\n",
      "Epoch 327/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0599 - val_loss: 0.0598\n",
      "Epoch 328/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 329/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0595 - val_loss: 0.0599\n",
      "Epoch 330/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0597 - val_loss: 0.0605\n",
      "Epoch 331/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0594 - val_loss: 0.0602\n",
      "Epoch 332/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0592 - val_loss: 0.0599\n",
      "Epoch 333/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0601 - val_loss: 0.0603\n",
      "Epoch 334/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0601 - val_loss: 0.0601\n",
      "Epoch 335/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0594 - val_loss: 0.0603\n",
      "Epoch 336/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0593 - val_loss: 0.0603\n",
      "Epoch 337/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0593 - val_loss: 0.0600\n",
      "Epoch 338/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0607 - val_loss: 0.0599\n",
      "Epoch 339/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0582 - val_loss: 0.0596\n",
      "Epoch 340/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0593 - val_loss: 0.0598\n",
      "Epoch 341/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0592 - val_loss: 0.0595\n",
      "Epoch 342/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0596 - val_loss: 0.0597\n",
      "Epoch 343/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0586 - val_loss: 0.0595\n",
      "Epoch 344/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0593 - val_loss: 0.0603\n",
      "Epoch 345/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 346/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0595 - val_loss: 0.0601\n",
      "Epoch 347/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0606 - val_loss: 0.0598\n",
      "Epoch 348/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0597 - val_loss: 0.0595\n",
      "Epoch 349/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 350/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0593 - val_loss: 0.0596\n",
      "Epoch 351/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0592 - val_loss: 0.0597\n",
      "Epoch 352/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0595 - val_loss: 0.0597\n",
      "Epoch 353/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0594 - val_loss: 0.0597\n",
      "Epoch 354/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0601 - val_loss: 0.0595\n",
      "Epoch 355/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 356/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0598 - val_loss: 0.0595\n",
      "Epoch 357/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0599 - val_loss: 0.0597\n",
      "Epoch 358/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0599 - val_loss: 0.0599\n",
      "Epoch 359/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0599 - val_loss: 0.0598\n",
      "Epoch 360/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0590 - val_loss: 0.0600\n",
      "Epoch 361/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0592 - val_loss: 0.0597\n",
      "Epoch 362/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0595 - val_loss: 0.0601\n",
      "Epoch 363/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 364/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0596 - val_loss: 0.0604\n",
      "Epoch 365/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0594 - val_loss: 0.0597\n",
      "Epoch 366/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0594 - val_loss: 0.0599\n",
      "Epoch 367/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0604 - val_loss: 0.0597\n",
      "Epoch 368/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0590 - val_loss: 0.0597\n",
      "Epoch 369/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0600 - val_loss: 0.0602\n",
      "Epoch 370/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0594 - val_loss: 0.0596\n",
      "Epoch 371/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0591 - val_loss: 0.0598\n",
      "Epoch 372/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0599 - val_loss: 0.0603\n",
      "Epoch 373/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 374/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0589 - val_loss: 0.0598\n",
      "Epoch 375/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0589 - val_loss: 0.0598\n",
      "Epoch 376/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0595 - val_loss: 0.0596\n",
      "Epoch 377/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0591 - val_loss: 0.0597\n",
      "Epoch 378/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 379/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0606 - val_loss: 0.0596\n",
      "Epoch 380/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0592 - val_loss: 0.0599\n",
      "Epoch 381/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0591 - val_loss: 0.0596\n",
      "Epoch 382/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0591 - val_loss: 0.0596\n",
      "Epoch 383/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0597 - val_loss: 0.0599\n",
      "Epoch 384/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0602 - val_loss: 0.0596\n",
      "Epoch 385/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0591 - val_loss: 0.0599\n",
      "Epoch 386/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0583 - val_loss: 0.0601\n",
      "Epoch 387/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 0.0592 - val_loss: 0.0598\n",
      "Epoch 388/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0595 - val_loss: 0.0598\n",
      "Epoch 389/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - loss: 0.0600 - val_loss: 0.0601\n",
      "Epoch 390/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - loss: 0.0598 - val_loss: 0.0598\n",
      "Epoch 391/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - loss: 0.0598 - val_loss: 0.0596\n",
      "Epoch 392/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0596 - val_loss: 0.0596\n",
      "Epoch 393/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0597 - val_loss: 0.0595\n",
      "Epoch 394/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0594 - val_loss: 0.0598\n",
      "Epoch 395/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0599 - val_loss: 0.0596\n",
      "Epoch 396/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - loss: 0.0600 - val_loss: 0.0596\n",
      "Epoch 397/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - loss: 0.0600 - val_loss: 0.0595\n",
      "Epoch 398/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0592 - val_loss: 0.0597\n",
      "Epoch 399/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0588 - val_loss: 0.0596\n",
      "Epoch 400/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0600 - val_loss: 0.0597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27a899d21c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Train the neural network with our data\n",
    "\n",
    " # using validation again for better metrics and optimization\n",
    "model_1.fit(x=X_train, y=y_train, epochs=400, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAGdCAYAAADqsoKGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkrUlEQVR4nO3deVhU9f4H8PfMwIAoi4oCKuK+IyoqYaWZFC6VpLfMvGlmll01l/Jescx2/FV6rdS8dVMrNdRbmqmZilsqbiju4hKKJpsi+z5zfn98meXAgCwHD8L79Tw8wMyZM+cww5z3+XyXo5EkSQIRERHRfU6r9gYQERERKYGhhoiIiGoFhhoiIiKqFRhqiIiIqFZgqCEiIqJagaGGiIiIagWGGiIiIqoVGGqIiIioVrBTewPuFaPRiJs3b8LZ2RkajUbtzSEiIqJykCQJGRkZaNasGbTasmsxdSbU3Lx5E97e3mpvBhEREVXC9evX0aJFizKXqTOhxtnZGYD4o7i4uKi8NURERFQe6enp8Pb2Nh/HyyRVwuLFiyUfHx/JwcFB6tu3r3T48OEyl1+3bp3UsWNHycHBQerWrZu0ZcsW2f0ZGRnS5MmTpebNm0uOjo5S586dpa+++kq2zIABAyQAsq9XX3213NuclpYmAZDS0tLKv6NERESkqoocvyvcUXjt2rWYOXMm5s2bh+PHj8PPzw/BwcFISkqyufzBgwcxevRoTJgwASdOnEBISAhCQkJw5swZ8zIzZ87Etm3bsGrVKpw/fx7Tp0/HlClTsGnTJtm6Jk6ciPj4ePPXJ598UtHNJyIiolpKI0kVu0p3QEAA+vTpg8WLFwMQHXC9vb0xdepUzJ49u8Tyo0aNQlZWFjZv3my+7YEHHkCPHj2wbNkyAEC3bt0watQozJ0717yMv78/hgwZgg8//BAA8Mgjj6BHjx5YtGhRhXcSEOUrV1dXpKWlsfmJiIjoPlGR43eFKjX5+fmIiopCUFCQZQVaLYKCghAZGWnzMZGRkbLlASA4OFi2fL9+/bBp0yb89ddfkCQJu3fvxsWLF/H444/LHrd69Wq4u7ujW7duCA0NRXZ2dqnbmpeXh/T0dNkXERER1V4V6ih869YtGAwGeHh4yG738PDAhQsXbD4mISHB5vIJCQnm37/88ku88soraNGiBezs7KDVavHNN9+gf//+5mWef/55+Pj4oFmzZjh16hT+9a9/ISYmBj///LPN5w0LC8N7771Xkd0jIqJaTpIkFBYWwmAwqL0pVESn08HOzk6R6VZqxOinL7/8EocOHcKmTZvg4+ODffv2YfLkyWjWrJm5yvPKK6+Yl/f19YWXlxcGDRqEK1euoG3btiXWGRoaipkzZ5p/N/WeJiKiuik/Px/x8fFlVvlJHU5OTvDy8oJer6/SeioUatzd3aHT6ZCYmCi7PTExEZ6enjYf4+npWebyOTk5mDNnDjZs2IBhw4YBALp3747o6Gh89tlnJZquTAICAgAAly9fthlqHBwc4ODgUJHdIyKiWspoNCI2NhY6nQ7NmjWDXq/nRKw1gCRJyM/PR3JyMmJjY9G+ffu7TrBXlgqFGr1eD39/f0RERCAkJASAeKNERERgypQpNh8TGBiIiIgITJ8+3Xzbjh07EBgYCAAoKChAQUFBiZ3Q6XQwGo2lbkt0dDQAwMvLqyK7QEREdVB+fr55YIuTk5Pam0NW6tWrB3t7e1y7dg35+flwdHSs9Loq3Pw0c+ZMjBs3Dr1790bfvn2xaNEiZGVlYfz48QCAsWPHonnz5ggLCwMATJs2DQMGDMCCBQswbNgwhIeH49ixY/j6668BAC4uLhgwYABmzZqFevXqwcfHB3v37sX333+PhQsXAgCuXLmCNWvWYOjQoWjcuDFOnTqFGTNmoH///ujevXuld56IiOqWqlQBqPoo9bpUONSMGjUKycnJeOedd5CQkIAePXpg27Zt5s7AcXFxso3r168f1qxZg7fffhtz5sxB+/btsXHjRnTr1s28THh4OEJDQzFmzBikpKTAx8cHH330ESZNmgRAVIh27txpDlDe3t4YOXIk3n777aruPxEREdUSFZ6n5n7FeWqIiOqu3NxcxMbGonXr1lVq3qDqUdbrU23z1BAREdG99cgjj8j6pVLpGGqIiIioVqgR89Tczy4nZWLVoWvwcnXEqwNKDi0nIiKie4OVmir6KzUHKw9exS/RN9XeFCIiKidJkpCdX6jKV1W6st65cwdjx45Fw4YN4eTkhCFDhuDSpUvm+69du4Ynn3wSDRs2RP369dG1a1ds3brV/NgxY8agSZMmqFevHtq3b48VK1ZU+W9Zk7BSU0WmqZvqRG9rIqJaIqfAgC7v/K7Kc597PxhO+sodfl988UVcunQJmzZtgouLC/71r39h6NChOHfuHOzt7TF58mTk5+dj3759qF+/Ps6dO4cGDRoAAObOnYtz587ht99+g7u7Oy5fvoycnBwld011DDVVZJqQso4MIiMiIpWYwsyBAwfQr18/AOJCz97e3ti4cSOeeeYZxMXFYeTIkfD19QUAtGnTxvz4uLg49OzZE7179wYAtGrV6p7vQ3VjqKkiDTjNNhHR/aaevQ7n3g9W7bkr4/z587CzszNfJggAGjdujI4dO+L8+fMAgNdffx2vvfYatm/fjqCgIIwcOdI8Se1rr72GkSNH4vjx43j88ccREhJiDke1BfvUVJGlUqPudhARUflpNBo46e1U+arOa069/PLL+PPPP/HCCy/g9OnT6N27N7788ksAwJAhQ3Dt2jXMmDEDN2/exKBBg/Dmm29W27aogaGmilinISKie6Fz584oLCzE4cOHzbfdvn0bMTEx6NKli/k2b29vTJo0CT///DPeeOMNfPPNN+b7mjRpgnHjxmHVqlVYtGiR+ZJFtQWbnxQisaswERFVo/bt22P48OGYOHEi/vOf/8DZ2RmzZ89G8+bNMXz4cADA9OnTMWTIEHTo0AF37tzB7t270blzZwDAO++8A39/f3Tt2hV5eXnYvHmz+b7agpWaqmLzExER3SMrVqyAv78/nnjiCQQGBkKSJGzduhX29vYAAIPBgMmTJ6Nz584YPHgwOnTogKVLlwIQ11EMDQ1F9+7d0b9/f+h0OoSHh6u5O4rjtZ+qKPLKbYz+5hDaNW2AnTMHKLZeIiJSDq/9VLPx2k81BId0ExER1QwMNVXEyfeIiIhqBoaaKjIPzWOqISIiUhVDTRUx0xAREdUMDDVVZG5+Yp8aIiIiVTHUVBErNURERDUDQ02ViVTDQg0REZG6GGqqqBov4UFEREQVwFCjEF4mgYiISF0MNVVk6Sis6mYQERHZ1KpVKyxatKhcy2o0GmzcuLFat6c6MdRUkWmeGoYaIiIidTHUVBG71BAREdUMDDVVxGs/ERHdhyQJyM9S56sCx4uvv/4azZo1g9FolN0+fPhwvPTSS7hy5QqGDx8ODw8PNGjQAH369MHOnTsV+zOdPn0ajz76KOrVq4fGjRvjlVdeQWZmpvn+PXv2oG/fvqhfvz7c3Nzw4IMP4tq1awCAkydPYuDAgXB2doaLiwv8/f1x7NgxxbbNFrtqXXsdoDEN6VZ5O4iIqAIKsoGPm6nz3HNuAvr65Vr0mWeewdSpU7F7924MGjQIAJCSkoJt27Zh69atyMzMxNChQ/HRRx/BwcEB33//PZ588knExMSgZcuWVdrMrKwsBAcHIzAwEEePHkVSUhJefvllTJkyBStXrkRhYSFCQkIwceJE/Pjjj8jPz8eRI0fM3TLGjBmDnj174quvvoJOp0N0dDTs7e2rtE13w1BTRZZKjbrbQUREtU/Dhg0xZMgQrFmzxhxq/ve//8Hd3R0DBw6EVquFn5+fefkPPvgAGzZswKZNmzBlypQqPfeaNWuQm5uL77//HvXrixC2ePFiPPnkk/i///s/2NvbIy0tDU888QTatm0LAOjcubP58XFxcZg1axY6deoEAGjfvn2Vtqc8GGoUwiHdRET3EXsnUTFR67krYMyYMZg4cSKWLl0KBwcHrF69Gs899xy0Wi0yMzPx7rvvYsuWLYiPj0dhYSFycnIQFxdX5c08f/48/Pz8zIEGAB588EEYjUbExMSgf//+ePHFFxEcHIzHHnsMQUFBePbZZ+Hl5QUAmDlzJl5++WX88MMPCAoKwjPPPGMOP9WFfWqqiJUaIqL7kEYjmoDU+KrgrK1PPvkkJEnCli1bcP36dfzxxx8YM2YMAODNN9/Ehg0b8PHHH+OPP/5AdHQ0fH19kZ+fXx1/tRJWrFiByMhI9OvXD2vXrkWHDh1w6NAhAMC7776Ls2fPYtiwYdi1axe6dOmCDRs2VOv2MNRUEfvUEBFRdXJ0dMSIESOwevVq/Pjjj+jYsSN69eoFADhw4ABefPFFPP300/D19YWnpyeuXr2qyPN27twZJ0+eRFZWlvm2AwcOQKvVomPHjubbevbsidDQUBw8eBDdunXDmjVrzPd16NABM2bMwPbt2zFixAisWLFCkW0rDUNNFfEyCUREVN3GjBmDLVu2YPny5eYqDSD6qfz888+Ijo7GyZMn8fzzz5cYKVWV53R0dMS4ceNw5swZ7N69G1OnTsULL7wADw8PxMbGIjQ0FJGRkbh27Rq2b9+OS5cuoXPnzsjJycGUKVOwZ88eXLt2DQcOHMDRo0dlfW6qA/vUKITNT0REVF0effRRNGrUCDExMXj++efNty9cuBAvvfQS+vXrB3d3d/zrX/9Cenq6Is/p5OSE33//HdOmTUOfPn3g5OSEkSNHYuHCheb7L1y4gO+++w63b9+Gl5cXJk+ejFdffRWFhYW4ffs2xo4di8TERLi7u2PEiBF47733FNm20mikOjLBSnp6OlxdXZGWlgYXFxfF1nshIR2DF/0B9wZ6HHv7McXWS0REysnNzUVsbCxat24NR0dHtTeHiinr9anI8ZvNT1Vk7lNTJ6IhERFRzcVQU0Xm0U/qbgYREVGZVq9ejQYNGtj86tq1q9qbpwj2qakiy1W6GWuIiKjmeuqppxAQEGDzvuqe6fdeYaipIlZqiIjofuDs7AxnZ2e1N6NasfmpytinhojofsGqes2k1OvCUFNFvEo3EVHNZ2peyc7OVnlLyBbT61LVZjA2P1WRuU+NqltBRERl0el0cHNzQ1JSEgAxx4qGs6eqTpIkZGdnIykpCW5ubtDpdFVaH0NNFWnYqYaI6L7g6ekJAOZgQzWHm5ub+fWpCoYaIiKqEzQaDby8vNC0aVMUFBSovTlUxN7evsoVGhOGmipi8xMR0f1Fp9MpdhClmoUdhauIHYWJiIhqBoaaKjJfJkHl7SAiIqrrGGqqyFKpUXc7iIiI6jqGGoVIrNUQERGpiqGmilipISIiqhkYaqrINE8NMw0REZG6GGqqyDwfJVMNERGRqhhqqsgyoTBTDRERkZoYaqpIw6t0ExER1QgMNURERFQrMNRUEa9nSUREVDMw1FSR+dpPbH8iIiJSFUNNVbFSQ0REVCMw1FQROwoTERHVDJUKNUuWLEGrVq3g6OiIgIAAHDlypMzl169fj06dOsHR0RG+vr7YunWr7P7MzExMmTIFLVq0QL169dClSxcsW7ZMtkxubi4mT56Mxo0bo0GDBhg5ciQSExMrs/mK0mjuvgwRERFVvwqHmrVr12LmzJmYN28ejh8/Dj8/PwQHByMpKcnm8gcPHsTo0aMxYcIEnDhxAiEhIQgJCcGZM2fMy8ycORPbtm3DqlWrcP78eUyfPh1TpkzBpk2bzMvMmDEDv/76K9avX4+9e/fi5s2bGDFiRCV2WVnWmYb9aoiIiNSjkSp4JA4ICECfPn2wePFiAIDRaIS3tzemTp2K2bNnl1h+1KhRyMrKwubNm823PfDAA+jRo4e5GtOtWzeMGjUKc+fONS/j7++PIUOG4MMPP0RaWhqaNGmCNWvW4G9/+xsA4MKFC+jcuTMiIyPxwAMP3HW709PT4erqirS0NLi4uFRkl8uUkpWPXh/sAAD8+fFQaLUs3RARESmlIsfvClVq8vPzERUVhaCgIMsKtFoEBQUhMjLS5mMiIyNlywNAcHCwbPl+/fph06ZN+OuvvyBJEnbv3o2LFy/i8ccfBwBERUWhoKBAtp5OnTqhZcuWpT5vXl4e0tPTZV/VQVapqZZnICIiovKoUKi5desWDAYDPDw8ZLd7eHggISHB5mMSEhLuuvyXX36JLl26oEWLFtDr9Rg8eDCWLFmC/v37m9eh1+vh5uZW7ucNCwuDq6ur+cvb27siu1pu1n1q2PxERESknhox+unLL7/EoUOHsGnTJkRFRWHBggWYPHkydu7cWel1hoaGIi0tzfx1/fp1BbfYQgM2NxEREdUEdhVZ2N3dHTqdrsSoo8TERHh6etp8jKenZ5nL5+TkYM6cOdiwYQOGDRsGAOjevTuio6Px2WefISgoCJ6ensjPz0dqaqqsWlPW8zo4OMDBwaEiu1dlrNMQERGpp0KVGr1eD39/f0RERJhvMxqNiIiIQGBgoM3HBAYGypYHgB07dpiXLygoQEFBAbRa+abodDoYjUYAotOwvb29bD0xMTGIi4sr9XnvGVnzk3qbQUREVNdVqFIDiOHX48aNQ+/evdG3b18sWrQIWVlZGD9+PABg7NixaN68OcLCwgAA06ZNw4ABA7BgwQIMGzYM4eHhOHbsGL7++msAgIuLCwYMGIBZs2ahXr168PHxwd69e/H9999j4cKFAABXV1dMmDABM2fORKNGjeDi4oKpU6ciMDCwXCOfqpOsTw1rNURERKqpcKgZNWoUkpOT8c477yAhIQE9evTAtm3bzJ2B4+LiZFWXfv36Yc2aNXj77bcxZ84ctG/fHhs3bkS3bt3My4SHhyM0NBRjxoxBSkoKfHx88NFHH2HSpEnmZf79739Dq9Vi5MiRyMvLQ3BwMJYuXVqVfVeEfJ4a1TaDiIiozqvwPDX3q+qapyYzrxDd5v0OALjwwWA42usUWzcREVFdV23z1FBJrNQQERHVDAw1VcQ+NURERDUDQ00VWc9Tw0oNERGRehhqqkheqSEiIiK1MNQoqI70uSYiIqqRGGqqSMOrJBAREdUIDDUKYp2GiIhIPQw1VcSOwkRERDUDQ00VyZqfGGqIiIhUw1BTRfJMw1RDRESkFoaaKtJo2PxERERUEzDUVBFbn4iIiGoGhpoqkk2+x1INERGRahhqqkjW/KTidhAREdV1DDUKYqGGiIhIPQw1CjAVazj6iYiISD0MNQrglRKIiIjUx1CjJBZqiIiIVMNQowBTZ2FmGiIiIvUw1CjA1PzEjsJERETqYahRADsKExERqY+hRgGmK3WzUkNERKQehholmCs1REREpBaGGgVY+tQw1hAREamFoUYB5j41zDRERESqYahRgIbT7xEREamOoUYBrNQQERGpj6FGAazTEBERqY+hRkGcp4aIiEg9DDUKMF8mgZmGiIhINQw1CjAP6VZ1K4iIiOo2hholmDsKM9YQERGphaFGAazUEBERqY+hRgHsU0NERKQ+hhoFaMxjuplqiIiI1MJQowDLtZ9U3QwiIqI6jaFGAebmJ5W3g4iIqC5jqFEAKzVERETqY6ghIiKiWoGhRgHmC1qyAYqIiEg1DDWK4JBuIiIitTHUKMBcqWGoISIiUg1DjQIsMwoz1RAREamFoUYBrNQQERGpj6FGARpzrYaIiIjUwlCjAFZqiIiI1MdQowD2qSEiIlIfQ40CeJVuIiIi9THUKIiZhoiISD0MNURERFQrMNQowNJRmLUaIiIitTDUKMBy7SciIiJSC0ONAjS89hMREZHqGGoUoDHPvcdUQ0REpBaGGgWY56lhpiEiIlINQ40CzPPUqLwdREREdRlDjQJYqSEiIlJfpULNkiVL0KpVKzg6OiIgIABHjhwpc/n169ejU6dOcHR0hK+vL7Zu3Sq7X6PR2Pz69NNPzcu0atWqxP3z58+vzOYrj0O6iYiIVFfhULN27VrMnDkT8+bNw/Hjx+Hn54fg4GAkJSXZXP7gwYMYPXo0JkyYgBMnTiAkJAQhISE4c+aMeZn4+HjZ1/Lly6HRaDBy5EjZut5//33ZclOnTq3o5lcLy7WfiIiISC0VDjULFy7ExIkTMX78eHTp0gXLli2Dk5MTli9fbnP5zz//HIMHD8asWbPQuXNnfPDBB+jVqxcWL15sXsbT01P29csvv2DgwIFo06aNbF3Ozs6y5erXr1/Rza8WvPYTERGR+ioUavLz8xEVFYWgoCDLCrRaBAUFITIy0uZjIiMjZcsDQHBwcKnLJyYmYsuWLZgwYUKJ++bPn4/GjRujZ8+e+PTTT1FYWFjqtubl5SE9PV32RURERLWXXUUWvnXrFgwGAzw8PGS3e3h44MKFCzYfk5CQYHP5hIQEm8t/9913cHZ2xogRI2S3v/766+jVqxcaNWqEgwcPIjQ0FPHx8Vi4cKHN9YSFheG9994r765ViaX5iaUaIiIitVQo1NwLy5cvx5gxY+Do6Ci7febMmeafu3fvDr1ej1dffRVhYWFwcHAosZ7Q0FDZY9LT0+Ht7V0t26xhpxoiIiLVVSjUuLu7Q6fTITExUXZ7YmIiPD09bT7G09Oz3Mv/8ccfiImJwdq1a++6LQEBASgsLMTVq1fRsWPHEvc7ODjYDDvVwXyZhHvybERERGRLhfrU6PV6+Pv7IyIiwnyb0WhEREQEAgMDbT4mMDBQtjwA7Nixw+by3377Lfz9/eHn53fXbYmOjoZWq0XTpk0rsgvVwnKVbnW3g4iIqC6rcPPTzJkzMW7cOPTu3Rt9+/bFokWLkJWVhfHjxwMAxo4di+bNmyMsLAwAMG3aNAwYMAALFizAsGHDEB4ejmPHjuHrr7+WrTc9PR3r16/HggULSjxnZGQkDh8+jIEDB8LZ2RmRkZGYMWMG/v73v6Nhw4aV2e9qwT41RERE6qlwqBk1ahSSk5PxzjvvICEhAT169MC2bdvMnYHj4uKg1VoKQP369cOaNWvw9ttvY86cOWjfvj02btyIbt26ydYbHh4OSZIwevToEs/p4OCA8PBwvPvuu8jLy0Pr1q0xY8YMWZ8ZNXFINxERkfo0Uh2ZBjc9PR2urq5IS0uDi4uLouse+vkfOBefju9e6osBHZooum4iIqK6rCLHb177SQEaXiaBiIhIdQw1CjCHGnU3g4iIqE5jqFGAxjz9HhEREamFoUZJLNUQERGphqFGAZbmJ6YaIiIitTDUKMB8lQRmGiIiItUw1CiB89QQERGpjqFGAbyeJRERkfoYahTAeWqIiIjUx1CjAFZqiIiI1MdQowBe+4mIiEh9DDUKsEy9x1RDRESkFoYaBVj61Ki7HURERHUZQ40CeJkEIiIi9THUKIiFGiIiIvUw1CiBzU9ERESqY6hRgGVIN1MNERGRWhhqFMCOwkREROpjqFGAqaMwMw0REZF6GGoUwMskEBERqY+hRgEajugmIiJSHUONAszNTyzUEBERqYahRgHm5if2qiEiIlINQ42CWKkhIiJSD0MNERER1QoMNQrQaNinhoiISG0MNQqwzChMREREamGoUQDnqSEiIlIfQ40CWKkhIiJSH0ONAjSWMd1ERESkEoYaBfAq3UREROpjqFEAr9JNRESkPoYaRfAq3URERGpjqFEAKzVERETqY6hRAPvUEBERqY+hhoiIiGoFhhoFsPmJiIhIfQw1CtCwozAREZHqGGoUoDF3qmGsISIiUgtDjQI4oTAREZH6GGoUYG5+YqohIiJSDUONEniVbiIiItUx1CiAV+kmIiJSH0ONAkxX6WahhoiISD0MNQpgpYaIiEh9DDUK0LBPDRERkeoYaoiIiKhWYKhRgObuixAREVE1Y6hRADsKExERqY+hRgGWjsJMNURERGphqFECr9JNRESkOoYaBfAq3UREROpjqFGAhpUaIiIi1THUKIB9aoiIiNTHUKMAVmqIiIjUx1CjAA1nqiEiIlJdpULNkiVL0KpVKzg6OiIgIABHjhwpc/n169ejU6dOcHR0hK+vL7Zu3Sq7X6PR2Pz69NNPzcukpKRgzJgxcHFxgZubGyZMmIDMzMzKbL7ieJkEIiIi9VU41KxduxYzZ87EvHnzcPz4cfj5+SE4OBhJSUk2lz948CBGjx6NCRMm4MSJEwgJCUFISAjOnDljXiY+Pl72tXz5cmg0GowcOdK8zJgxY3D27Fns2LEDmzdvxr59+/DKK69UYpeJiIioNtJIFSwvBAQEoE+fPli8eDEAwGg0wtvbG1OnTsXs2bNLLD9q1ChkZWVh8+bN5tseeOAB9OjRA8uWLbP5HCEhIcjIyEBERAQA4Pz58+jSpQuOHj2K3r17AwC2bduGoUOH4saNG2jWrNldtzs9PR2urq5IS0uDi4tLRXb5rkJ/PoUfj1zHG491wNRB7RVdNxERUV1WkeN3hSo1+fn5iIqKQlBQkGUFWi2CgoIQGRlp8zGRkZGy5QEgODi41OUTExOxZcsWTJgwQbYONzc3c6ABgKCgIGi1Whw+fNjmevLy8pCeni77qj6cp4aIiEhtFQo1t27dgsFggIeHh+x2Dw8PJCQk2HxMQkJChZb/7rvv4OzsjBEjRsjW0bRpU9lydnZ2aNSoUanrCQsLg6urq/nL29v7rvtXWRz9REREpL4aN/pp+fLlGDNmDBwdHau0ntDQUKSlpZm/rl+/rtAWlsR5aoiIiNRnV5GF3d3dodPpkJiYKLs9MTERnp6eNh/j6elZ7uX/+OMPxMTEYO3atSXWUbwjcmFhIVJSUkp9XgcHBzg4ONx1n5TASg0REZH6KlSp0ev18Pf3N3fgBURH4YiICAQGBtp8TGBgoGx5ANixY4fN5b/99lv4+/vDz8+vxDpSU1MRFRVlvm3Xrl0wGo0ICAioyC5UC177iYiISH0VqtQAwMyZMzFu3Dj07t0bffv2xaJFi5CVlYXx48cDAMaOHYvmzZsjLCwMADBt2jQMGDAACxYswLBhwxAeHo5jx47h66+/lq03PT0d69evx4IFC0o8Z+fOnTF48GBMnDgRy5YtQ0FBAaZMmYLnnnuuXCOfqpvG3P7EWENERKSWCoeaUaNGITk5Ge+88w4SEhLQo0cPbNu2zdwZOC4uDlqtpQDUr18/rFmzBm+//TbmzJmD9u3bY+PGjejWrZtsveHh4ZAkCaNHj7b5vKtXr8aUKVMwaNAgaLVajBw5El988UVFN79aWPrUEBERkVoqPE/N/ao656l5d9NZrDx4FVMGtsObwR0VXTcREVFdVm3z1FDZOPqJiIhIPQw1REREVCsw1CiAQ7qJiIjUx1CjAA7pJiIiUh9DjQJYqSEiIlIfQ40CeJkEIiIi9THUKEDDiWqIiIhUx1CjAI2GfWqIiIjUxlCjAMtVEhhriIiI1MJQowR2FCYiIlIdQ40COKSbiIhIfQw1CjB3FCYiIiLVMNQoiM1PRERE6mGoUQDnqSEiIlIfQ40COKMwERGR+hhqFKABO9UQERGpjaFGAZZKDUs1REREamGoUQCvkkBERKQ+hholmC6TwFRDRESkGoYaBXD0ExERkfoYahTA0U9ERETqY6hRAC+TQEREpD6GGiIiIqoVGGoUwOYnIiIi9THUKMAy9R5TDRERkVoYahTASg0REZH6GGoUoOE8NURERKpjqFEQ56khIiJSD0ONAtj8REREpD6GGgVwnhoiIiL1MdQogJUaIiIi9THUKIDXfiIiIlIfQ40CNJZUQ0RERCphqCEiIqJagaFGAewoTEREpD6GGgVYOgoz1hAREamFoUZBjDRERETqYahRAC+TQEREpD6GGgVw8BMREZH6GGoUwD41RERE6mOoUQArNUREROpjqFGAxlyqUXc7iIiI6jKGGgVYMg1TDRERkVoYahRgbn5ipiEiIlINQw0RERHVCgw1SuA8NURERKpjqFGAZfQTUw0REZFaGGoUYJmnRt3tICIiqssYahTAq3QTERGpj6FGAazUEBERqY+hRgEa809MNURERGphqFEAKzVERETqY6hRAPvUEBERqY+hRgm8SjcREZHqGGoUwKt0ExERqY+hhoiIiGoFhhoFaHiZBCIiItVVKtQsWbIErVq1gqOjIwICAnDkyJEyl1+/fj06deoER0dH+Pr6YuvWrSWWOX/+PJ566im4urqifv366NOnD+Li4sz3P/LII9BoNLKvSZMmVWbzFcfmJyIiIvVVONSsXbsWM2fOxLx583D8+HH4+fkhODgYSUlJNpc/ePAgRo8ejQkTJuDEiRMICQlBSEgIzpw5Y17mypUreOihh9CpUyfs2bMHp06dwty5c+Ho6Chb18SJExEfH2/++uSTTyq6+dVCw47CREREqtNIFTwSBwQEoE+fPli8eDEAwGg0wtvbG1OnTsXs2bNLLD9q1ChkZWVh8+bN5tseeOAB9OjRA8uWLQMAPPfcc7C3t8cPP/xQ6vM+8sgj6NGjBxYtWlSRzTVLT0+Hq6sr0tLS4OLiUql1lGbDiRuYsfYkHm7vjh8mBCi6biIiorqsIsfvClVq8vPzERUVhaCgIMsKtFoEBQUhMjLS5mMiIyNlywNAcHCweXmj0YgtW7agQ4cOCA4ORtOmTREQEICNGzeWWNfq1avh7u6Obt26ITQ0FNnZ2aVua15eHtLT02Vf1cU8Tw0LNURERKqpUKi5desWDAYDPDw8ZLd7eHggISHB5mMSEhLKXD4pKQmZmZmYP38+Bg8ejO3bt+Ppp5/GiBEjsHfvXvNjnn/+eaxatQq7d+9GaGgofvjhB/z9738vdVvDwsLg6upq/vL29q7IrlaIufmJvWqIiIhUY6f2BhiNRgDA8OHDMWPGDABAjx49cPDgQSxbtgwDBgwAALzyyivmx/j6+sLLywuDBg3ClStX0LZt2xLrDQ0NxcyZM82/p6enV2uwAVipISIiUlOFKjXu7u7Q6XRITEyU3Z6YmAhPT0+bj/H09CxzeXd3d9jZ2aFLly6yZTp37iwb/VRcQIDou3L58mWb9zs4OMDFxUX2VV04pJuIiEh9FQo1er0e/v7+iIiIMN9mNBoRERGBwMBAm48JDAyULQ8AO3bsMC+v1+vRp08fxMTEyJa5ePEifHx8St2W6OhoAICXl1dFdqFaWIZ0M9UQERGppcLNTzNnzsS4cePQu3dv9O3bF4sWLUJWVhbGjx8PABg7diyaN2+OsLAwAMC0adMwYMAALFiwAMOGDUN4eDiOHTuGr7/+2rzOWbNmYdSoUejfvz8GDhyIbdu24ddff8WePXsAiCHfa9aswdChQ9G4cWOcOnUKM2bMQP/+/dG9e3cF/gxVw6t0ExERqa/CoWbUqFFITk7GO++8g4SEBPTo0QPbtm0zdwaOi4uDVmspAPXr1w9r1qzB22+/jTlz5qB9+/bYuHEjunXrZl7m6aefxrJlyxAWFobXX38dHTt2xE8//YSHHnoIgKjm7Ny50xygvL29MXLkSLz99ttV3X8iIiKqJSo8T839qjrnqdlyKh6T1xxH39aNsO5V281wREREVHHVNk8N2abhdRKIiIhUx1CjAHYUJiIiUh9DjQLYUZiIiEh9DDWKKJqnRuWtICIiqssYahTAq3QTERGpj6FGAewnTEREpD6GGgXwMglERETqY6hRACs1RERE6mOoISIiolqBoUYBlsn3WKshIiJSC0ONAsyjn9TdDCIiojqNoUYBGrCjMBERkdoYapRgrtQw1RAREamFoUYB7FJDRESkPoYaBXCeGiIiIvUx1CiA89QQERGpj6FGAbz2ExERkfoYahSgMddqiIiISC0MNQqwVGrU3Q4iIqK6jKGGiIiIagWGGgVYOgqzVENERKQWhholsPmJiIhIdQw1CjBfJkHl7SAiIqrLGGqqKjUOnjHf4yntAQ7pJiIiUhFDTVUlX0TrI+/iFbstrNQQERGpiKGmquwcAAAOKGD7ExERkYoYaqrKvh4AwBH5zDREREQqYqipKlOlRlNQ/j41hgIg61Y1bhQREVHdw1BTVXaOAACHilRq1r4ALOgEpN2ots0iIiKqaxhqqqoo1DiioPzz1CSdBYwFwO3L1bddREREdQxDTVWZKjWagtJn38vPlv9ekFv0PacaN4yIiKhuYaipKntHy4/IK3n/jSjgYy9g+1zLbYWmUJNdcnkiIiKqFIaaqrKzhBq9VFDy/h3viO8Hv7DcZqrQsFJDRESkGIaaqtLZQ9LoAAB6Kb/k/cZiQcdosNzGUENERKQYhhoFGHViWLfNUGMoFmqsgwybn4iIiBTDUKMAqSjU2JenUmPqTwOwUkNERKQghhoFGIv61ehhK9QY5L+zUkOkDKMBuHW59FGHRFTnMNQoQKpI81NlKzV3rpYMSER12abXgcX+QPQatbeEiGoIhhoFSOZKjY0h3cWbnypTqbm8E/jcD1gxlE1WRCbRq8T3vfPV3Q4iqjEYahRg6ShsY0i3oVD+c2UqNQmnxffrh4BtoZXcSqJaSmun9hYQUQ3BUKMAqcw+NVZBpzCnWKWmnKGm0KoCdO1AJbaQqBZjqCkpPR74ZTJwM1rtLSG6pxhqFGDuU2Mr1FgHkoKcYpWacjY/5WVYfs65U4ktJKrFiuaJIiu/TAZOrAK+HqD2lhDdUww1CpBKa36SJHkgKciuXKUmP8vyc84djvYgMhotP7NSU1J8tNpbQKQKhhoFmJqfHIp3FM7PAiSrEUuVrdTkZ1p+NhbKfyeqi/LSLT9r+TFWgmS8+zJEtRA/DRQg6Yr61BSv1Fh/8ALKVGoANkER5aRYfi60MeqwuiRfvLfPV1kMNVRHMdQowFKpKdanJrd4qCleqSlnqLFuwgIYaoiyrf4Hiv+fVZcLW4AlfYD140ved/F3YGk/IP7kvdmWu2ETNdVRDDUKkOxEnxpHKVceVEpUaoqPfipv8xMrNarLzwaWDwYi3ld2vTG/Af97CchNU3a9tZ31/0Dx0F9dDn0lvsdsKXnfmmeBpLPAurH3ZlvuhhN1Uh3FUKMAU6XmRWwClvS1fOCWqNRkV65Scz+EmuwU4MpueQdOpaTHi/VXVfQa4OTayj322gEgLhL4YwFw55q4LeE0sOtDIK8KfZx+fA448xNw+D+VX0dlXd0PpP11759XCdbNT/kZ9+YgXt/97stkJlX/dpQHm5+ojmKoUYCpTw0AIDUO2FM0w2lesbPv4pWawtzyhQBTx2CX5uK7daiJ+Q34T3/R1l+dbl0Gdn1UeqBa+QTwQwhw9ufKP8fF38VQ1HyrClZuGrAkAPiyV9X6MsSfBDa+Bmx4Rb7+8rKuqh1bLr7vDgP2fQqc/7Vy21Ro1Vx5r4Nq0gVg5TBRJbofFf973YtqjZNVqMlJtb1MTamQMNRQHcVQo4Si5iezY8uBjMS7V2oAMSFfcYlnRdXDxBRqXFuI76YPdKNRnOnHnxQVhOr030HAvk+A7XNt3590Vnw/u6Hyz7H3/8TcGlciLLel/CnCYc4d4OzGyq87aqXl59zUij/e+iB2YpXos5ARL37PuFm5bUq+YPlZp6/cOirrTmzR96v39nmVUrxyV7yptzpYB4XUa3dfRk3Woy7Zv4bqEIYaBZian8wM+UDy+bv3qTHdVtxX/UTVI+XPorluTKHGW3w3hZo/rYKProJzdVz83RKcrkUCGyYBWbdKX94UBK4dLHmf9UU77Z0qth3WspLFd+sSftZty89Hvq7cenPTgFPrrH6/ywEw/SZw/aj8NuvKQPYtEVBNt1lvY0UknpGv814y9eG5F2GgOuQUCzVV6Sx84xjw3ZN37+RrPZVCaWFQqoGVmvthtBaRQhhqFFC/fv2SN2YkioOjNVuVmuKdha0Pnneuig8k0welW7FQc2KVZdmKNKnk3AHCnwd+HC2aQFYMBk7+CPz2z7s/Vu8kDvjW5f6065afNVV4S5nOvrOtQoIp6ADAX8cq12dh/7/lB6S7Hci/eRT4Ngj4K8pyW/HqTnaK5cBa2UBiuqYXUHagrA6mylNBdskryd8PSjQ/VSHUrBsHxO4Dvnuq7OXyyhNqKlGp2fgPYGmgcherlST5dpR3QAJRLcBQo4B69RqUvDEjHkgoOhN3dBXfbVZqioWcO9fk91kfjM19alLF98SzlvusD/53c/uKmMSvMAdIv2G5/cZR28tbB6aE0+KAHz7GcltKrNV2FIWOwnzg8NeiClQehXmWfbU+wBffr4qGmvSbQORS+W13G2lkalay7lRcvA9FVrJlPRX521uThZpKrqOyrP8G92pIdFVd3G75mxVvfjLtQ26a6Gf21/Hyr9f0P3C3Zsl8qyBvHWqq0rxjNALRq4Gkc0DsH5Vfj7XinzHFBxoQ1WIMNUoo3qcGKAo1RR/ALfqK78XnqQFKnkVZf1hm37Ic6O2dLKMvTGep1pWgipzpWz9Hapzl59I+/KwrMSaxey0/p/xp+TkzSYSxbwYCv80CNk4q3zZZH6RKq9TY+h0QAaq0A0vcIcCQB3j4Aq0eFrfZCjWGQmD1M8BWq2rV7UuWn4sf8Kz3uTJVFqNB3tyRWY5Qk5EAbJpavrlQ7tZhVRZqUu++PrWl/AmseQZY85z4vXh1LC9DfH3RS/QzWzGk7BFzOaliVB0AOHtZbjcUlv4Y6+qk9clHVZp3rN/rGk3l12Ot+IzjrNSUX9Zt8Rlw+4raW0KVxFCjBKs+NXG6luKHG8dEB1etPdCsp7itILtkZab4WZV14Ig/CRz4Qvysrw/Uayh+zrkjDkrWZ46mg73RCOx8T1RJSnPHqrIiCzWlfPhZL2PNFK6sKzUZCWI0kKm/iKkJ7W6sP9ytD1jFA0Px31OvAws7AetfLHu9jVoBDi7iZ1tNFdcOAJe2A0eshlZbjygrXqmx/tDLrkSfmqRz8u3ISr77Gf+2UOD492K0m0nCGeDKLvlyqdeBT1rLA1px1kGmJvSrMRpFM8zWWbbvN50gpN8QYcUUSBq2Et/z0sTfwvTeKcyVNx8W982j4n2TdQtwcLbcfquMUYTWzU/W/xO2+s6Vl3Unc6VGcBVfT1UrNZIk+qRZV4Zrq53zxGfA0gfU3hI5SQJ+mghseI0dv++CoUYJ9pZQczTfR/zw1zHxvUlHefNT8dFOZVVqjv4XOPat+FnfwBJqslNK9tfJvi3OzmP3APsXiipJ8QBlkmL1HMkxlp8Lc2z/w5Q20sN0oLEOSdm3xQHbWtoNlJCZJK8mWHf8zKpApWb3R+I5z220ve2ms3WnxpbXwValxtaBPf2GCGmAJcCZRindvizfpop+0MQdEt+9A8T3wpy7H3ysOxYD4jmXPQj88LS8crR/odjHI2XMfXO35qecO6KJ8dwmy3Md+AJY+/fyHSQLcsRotfIeqJPOiWaYI1/bnjvHOmAmnbc0czbpJL7/dbzk3+fmCdvPlZ8NpBSF0iu75KE04VTp22hdATG9L4CS+5gSC3w9EPj9rdLXZWL9f6zUsP7i21PVSs3NE8DPE4ENr1ZtPfcD02eaIV98dmQmic+j7BTRrBl3WJ1QkZUMnF4HnFxTdmU46QIQX8Z7uA5gqFGCVaXmlLGN/D5PX0voqWilxpq+gaVMnploOYi5dwSgASCJf7yL2y2PsT7wlvYcxc9m33MDjq0otnwpocb0zyN7Hqlk35yNrwGrnwWuHhC/nwwHPmsP7PrAsoysUmMj1JjOyK1DjSTJ+yFkJpbcRtO6nBoDjkWVGlsH8dI+KK4fKXpMqvjeqOj1TbGq1BjybR+8E86IYGrrQzCuqK9R20GAXb2ibbhLE1S9RpafC3LkYdO6cmRrX67uF5UeU9XMuvJkK+Tt/QS4sBlY94L4/fc5wI65ogr3596Syxf3+1vA+nHAttl3XxaQv2duHCl5v3UF5ep+8V2nt7wvolcDW9+UP6a0UJNpFUhuXZI3U5XVtGddqcnPsLzmxf9+R/8L3DwOHFoqDz+23ItQU5l5mayZ3lvWJ0O1lfUV30+vFx24vx4ArBopmjWXP172vFTxp4Atbyrf8d/Uzw+Q94O0ZigAlgYA/3m4Ts9QXqlQs2TJErRq1QqOjo4ICAjAkSM2PoSsrF+/Hp06dYKjoyN8fX2xdevWEsucP38eTz31FFxdXVG/fn306dMHcXGWEm9ubi4mT56Mxo0bo0GDBhg5ciQSE20cxNSgtTf/2K7Hw/L7PLtbhjlbV2rsrIKONeuqhzWHBkD9JkVNKJLlg92tJeBUdLDLShIHIhPreVBkz3HV8rOtEv3m6fLfS2t+SjglDgimA47p7xBXrHPw9cPApd+BlUPFKBPTGd/+f1tCXfHmJ1MQMH04NOlc9LvVgf/GUfk/uKkZ7PyvYjLAtBuW5ginxmU3P1l/aFgzHRhNIaBha/G9eGA0bXPE+8CZogkIlz0IbHlDzBhcXNxh8d0nEGjQRL6vpbEe0XLrYrE+OVYdqK0/0PIyxXatHCYOske+sbGMjb+H9XvHUGh5HACkl2MWYlOF0XqEXlluHLP8XHw4PSAPNab+XC7NAPf2JZf1fVZ8N712V/cDCzpZXpd0q9f6zz0ArEKnqXJ54Avg4JeW2yWpZF+VjKLPn+Ih4vT6oscYLT+XpjyhJje9YoGnRJ+acjY/7f5YHJCLj4Yz/Y/lZ1Rt9uz7gXXFc+d74v867boIqSbWn7HF/bEAOPqNGE1aVl+/ishJlVe7U636OGanAJteF/8z1p9J9+v8UwqocKhZu3YtZs6ciXnz5uH48ePw8/NDcHAwkpJsj0o5ePAgRo8ejQkTJuDEiRMICQlBSEgIzpyxlIqvXLmChx56CJ06dcKePXtw6tQpzJ07F46OlgrIjBkz8Ouvv2L9+vXYu3cvbt68iREjRlRil6uBVeffJx8Lkt1laPMoYC/OxI35VpUat6JmKuvAYCiUv2Gt6euLjoSN24nfTWfLrs1F2AFEhcW6U6/pA9potBzECvPkByVDsYtwFpfyJ3A5wuZdqRf2YtW6cPGLewfAo0vR8xV1tmzZr+SD1o2T/36+6APC+gKFpsqHJFlCTFNTqLE68F8/XHJbAdFEcvUPMQOyuVLjbml+unMNuFEszBVvzjO5eUL+9zNVaoqfCWXdEk0gfywANs+Qd/yNj5Yvm3PHcqBo1svy+t2tUmNdYUg6Lw81h5aKJo/Ec8U6kCfJP5BNTYPWfWpsndVZVxTvxAJGqwNd8QB4cq0IqyaV+SC3rtQc/a+YR8nEaBQVFZNrRRU/52ZA7wnAyxEQ1coi3UaKqQUy4kWAWTlM/LxpasntL14VSrkiXrsdc4Htb1uqOPlZMIcf0yhE03qKh0Lr30+GW+aauhldcr+tt8XWLMVGA7C4N/BFz9Kbk4srHjzKU6nJTROTXx79RgRxa9bvJ1vV0OqydZbo+F3a/6bScu7Im8GLh0Fd0YCQsi4HYwoTp9cDH3mKimdVJJ0XVe21f7fcZh1wfn8LOP6dGJGadN5ye2nHkbLkZ4trl5kmcr26X3yGltV5vgaqcKhZuHAhJk6ciPHjx6NLly5YtmwZnJycsHz5cpvLf/755xg8eDBmzZqFzp0744MPPkCvXr2wePFi8zJvvfUWhg4dik8++QQ9e/ZE27Zt8dRTT6Fp06YAgLS0NHz77bdYuHAhHn30Ufj7+2PFihU4ePAgDh06VMldV1CLPqKZqftzcHNrKLvrpc1p2HlJfMhdvJEEg6ky0ayH+G7dpyX5fOmTd5kOPKYzU9MMvi5WoeZo0dm0aa6YWzHi7HRhJ2B+SxEgTq0DIN19PhnTB+Om18UZWstAQG/pUJmrqw+3/AQE/ik6Ml929IWhflP5Oto8UnK9pg8NUzj77Z/AuV9KdrbNviWCjaGouaSpjUpNUrFK1J1YeT+dzETbzU+XdwD/fVReHSj+wdm46O/8524grDnMB7RGrUvuEyBCjam6kZsqr85kJot2+f+9JJrgTM159ZtaKnCApZ+ILZJkqQwAIpxYh5rEMyK8LHuo5Gg061meTR98d+1TY/XhbgoRJtaVjqTz4tIT1pPXWT9/eSZjzEkV71UTQ564QKSpGplx03a1waWZCPotegM+D1pu9/ITIRsAzvzPcrvpvWGrSci+aK6p1Djxf2iSdl0sb7qYpUZrCbam9dhqenTvIA6CiWfE+2zzdNGMUXxWbOsTDFvVmNQ48T7OuVN6Fbe4Eh2XyxFqrJuYj38nwrGJdR+nuzWnKcVoEP2rUq4Av/3r3jynqdJrfQJkbch88T7JSrJ8/hZnChzxJ8Vn+Z6Pq7ZNER+IkzzrKq31iav1yYQs1JRSXS/LiVXiszjiffH5v3KYmEX+xPcVX5eKKhRq8vPzERUVhaAgSzVCq9UiKCgIkZG25yOJjIyULQ8AwcHB5uWNRiO2bNmCDh06IDg4GE2bNkVAQAA2btxoXj4qKgoFBQWy9XTq1AktW7Ys9Xnz8vKQnp4u+6o2dnpg0n5ghLxj5mWpOfZeuoVvj4iDkX1hFgpyRFiI1YuD5rWY45i1/iR2xyRBMvXfcGtZ4ikKU67h97MJyKjfSn6HSzP5hfZ8HgSe+xEAICXHIOO398xnV9KeMGDTFADAuaZPoEBjmZrf6OaDO06Wdc/5diPW7IkWFQ8AG1vPRV6B5Wx9ed4gAEBbrTjALf2zCX6+bHWG3sDTEkQAoMNg+XY/853o5JmTAmycXPKAnp1iCTD29S2VLeuRUaaqQ/Pe4nvKn/IDqtbOqqNwI0vzk4l1n4vi1QeffoBGJ342HRTs6smH/1rLSpYPAT/6X8vPyReA4ytF0Nk739IXpmHRPpkuf3G9jGbcnDuWgAeIg46tM3/JIA/GmYnABaurSieeEU1+1ge+4pUao0E+os0ULkysR+xYV1h+fkU81rpJsyC79Pb9lD+BVX8TzZCAaNpraBUa/9wjvpv6blmFagDivW9impgSAJw9gaZFVcPtb1tuN+SL8Gr9HjHx6CoCmGSUVybvXAN2zAN2f1i0DVZ920zvGVuh0G+0qBgB4r1gaoba9aF8OeuAaCvUWDe7mYJ3TqqoAJRWwSje/FSejt3FBwP8ZR34rSoD1v8n14+IZl7rEzOTqO/EFAnFR+aVl/VrdPF35as1tiot5n6K7UtWmd1aitezdVH3gugfSz6+IMf2RJyVmTA09g9RebWeNd7EOtRYv9bWo9PKG2okyRJUz2203G5qPgZKVrVruAqFmlu3bsFgMMDDw0N2u4eHBxISbCf4hISEMpdPSkpCZmYm5s+fj8GDB2P79u14+umnMWLECOzdu9e8Dr1eDzc3t3I/b1hYGFxdXc1f3t7eNperFr1EE4v2yUXo27oRYo2eAEQAcNQUIEtywKQDYsK+pnlx+F9UHMavOIqIHaIDWrznoyVWacy6jVd/iMK8A/Lh0W/8fgvnYy1v8sNd38K/T4u+LZrkC3DOumq+T1M0OmSvoTueuPYsjhW2M9+3/I4feqZ8jKNGcYabfuMCIraLkS9XjF6Y/nsqdEZLU9X3hY8hVycOMhI0iHHsjtV5lqHGhdl38HmUZVt3uTxt2ehGbQHPbiIIOrqJSpDpAGaSdcvyYVDf3RLcTM1PRiOkog/TpOYiYGUlXMKxQ1brSbshq9Tk28sPiql/xSA9tyioFe8n4uxZsmomGSz9l4rLSpI3kVgHnFsXLZPBJV2wlKhNQa37KPH9zE+lz61SvOx/9Y/yzWR8+7L8AGHIt4y8MonZIs7QTNKuywKUZOqM3bSr+G59ILYOhskXRH+X4h3FU68XzXJbrFnqj4WianZgkfi97aPAhB3Ag9PF79cixWNOF13iwm8UjE5NLI93aYb8QiMir9zG8ZbjYdA54pjTw3j260PYn1GsagiI129hZ/kHtkl9d0sF5pJVZ/vUOPkBXt9AvDeAsis1XYYDfV8WP58Kt9xePHDcrU+NdWAwVQF2fyS+vh9ecnlb21O8UmM0luxzUfwgaF0FLK356fvh4n3442j5Y7Nui+rKpe1iZN6FYn0o9/9b9N8xvR8kSbxHTUHj3C9ApKWSD0Me8M0gcVFdQFQn7jaPzJFv5E2Y1mK2AZ+1E00tRoPo+5KXYQnyjdpYmtIB4F9XgemnRfWm11hx26ElwKWd8vWWdsX74v9vZTn+g6jofveEqLzaqrIlnBEnNKbtNrlstT2ljVgFgP2LxKABoxE4vAxY0BHY+6m8IrvjHcvPpXW4r6FUH/1kLHojDx8+HDNmzECPHj0we/ZsPPHEE1i2bFml1xsaGoq0tDTz1/XrlWhjrKyhnwJvxKBN78ex7tVA7Hh3NCRvy7wHZ10eRo5LO+TDDvU0+Zjm7wgnvQ5tc0XlIfSU/AO5QNLhjYLX0KJhPZwvsATEPMkee1Ob4oc0PwDADkMvjPo5FZ8fy0GyZCmfZmnlFYpoez883MED+W0sla+EQmc4O9qhcUvxz/z39gV4pon4oLvo2B0aDWCnsZzdvDzsIThMOQAEfwzN35bjp9DnoG/VF/sN4sD3Y/7D+PqspZ/DK/vr4apRbPshqQt+irqB62kFyGlWNDFhUfiQit6Svx89gxtnRYXgVJ4H/vlb0YE0PxNJH3XB/E/eh6YgC/mww/g/xL4aki/j5CHLWbYx6Zy5v1OPBcfxtxXykvHR48fR/d3tGPrZthLVhKOJEo54T5DdBkM+pm2Sf1gk1BMVtxMHtiHparEhxSYF2ZbOhVlJ2L9XHDSNrqIil+vRC1mNugKFuTAeXIykjFzEp+Xg97MJ+CHyKnZfSELsVfEhnuPcCkat3rxfhQ5Wr3P9lijo+qzsqXMuiL/HHbsmiLLrAQDY91u4bBmkxgHrxiL/3z0R+92rSL4orxhpivryHJGKhk/fisH+L19GdPj7KLwszsSNRSOzjv+6DLeiNsoef/PQOuQu7IGUJY/hp0MxeHnlUfQP247sU7/Illt6oyWu59dHfOuivnLX9ovReEXNZ5PPd8NX6YHm5d+KSMHAz/Zg9DeHMGL9LfTJWoQxKRNwJDYF312WN3slSW4oLrmZ1cmDU2NL06L1lATJ5+UHUAfnkpWa4s09Hr5A47ZAc/+i0YlWMhIs77UbUfK5poqHmjtX5QeUtBsiAJg6bd+6KD8ZMBrEQa543yzrSo3RKEa0fe4nb5Y0NT+Zri9nCjWFefL1/T4HWD9eNKmaDrgpxQJG1HL51BWmShwgmlB3viv67xRVgXHiB9FnKPJLEf7XjbVcgLZ1f9EUnHET2PW+qAJ+96QIVKa+Hil/ilnDTSP74k+KkXBrnpU3yQAiKIePLpoG4hdROVv7d2BhF+DiNrFM47ZA16L3oHsHy1QaANBpGNCnKKz+sQA4tAy4tEP8nlZKdaS8oSYvU1TSbQ0ssHYnVjRl7pwnP/GyruTGbBUVxuJ9azKTxeMOLRVh3dSRv6xmsqRz8pOtlD/LN1moSip0FUR3d3fodLoSo44SExPh6elp8zGenp5lLu/u7g47Ozt06dJFtkznzp2xf/9+8zry8/ORmpoqq9aU9bwODg5wcLAx0++9YOdgOZsD4OxoD/j+Dbgu3tx9n3wV+zo8BiztCCSdxfSYFzBxxFeov1H8nWLsLB+ER92G4J85L2LSE12wyN8b4Qe9kLdTDwfkI7ZfGD71CcLFm72wNSsQu7Jaw+PPVLRt0gBXGs5AkzPvAgDqD5gKaffH0BT1C5n2/NNAu75AshuwRPSJGdarDV4f9ihcjp4FbmzEA87JQEEskAYED30ax9oFAZufAC5shuTVAy8/XHRWGzgZAOAIYOX4PjhwfjU2HvsRX1xuhZZeHvhf1y1IyCxExzgddiX1xEvabVia2AX71p+EVgO8rG2MOZbBYzht9EF3bSzcLq7HBakeWuiAzeltse5OKj4p6jfetOAvzC4QH5RXjF64JDXHLckF7pp0TLD7zbwubdH+5kn2SC20R0ON/EDXSisqQTm3bwDF3iprTmVgs3EA2mnaIcz+v+ihFR/cB/6SxM4W+U/6A5hnfwm+ucdloQ8Adhp6ooXmFjpp5R8s/nlHAA0QuicDEYd3wElvh+6pj2Kx/izwx0J8szseqw1B6K2NgSuyMNfYDyO0f2ChHjia6gwnTSv01opmiVVZAXjRToSko+kN8fKJEAQ4BaJ/wT68qtmAen+Js68Tec0RbWwHf/totEneKetXa6JP+xOt0/7E9SsRNk93Vv7VHH2LWiwfur0esOoGNSPtOXyuX4peqeLsOFNyxFFjRwzUnUSz6M8BAI4ZVzFyW188IdnjjNQKTlp5GPjqanN88sluABKuFrtG7FmjD7bcaoqTmkcx2U5UEC9k1sNfUg7cnOzh4eyIfEN9PNaqEXr5uGHDrnSg6LiaKLlhv7EbRurkzWgfXu2Ez/UilK0/lQKdgxOKDz3IPL0FDaxGR51LMeL8pUKMBJCWfAOpt7PgmZUKBwD5rR6FPvk0MvtOxbr9sfBt4Yo+7QbJ+wuZpjxoPcDcFIyWgWLEYM4dEVo0GhTeiIbdt4/KD1ppN4pCjlXFa++n4sDk4CwONtYhx6uH6KRuCjVGgzgDNwXsiA9E8HJpYTmz7/ykOODdOCaaM2z1iTr7s+VAbhKzTfQTrN8UOFpUCXv8QzGC6MYREVaa95KHtENfidASvUb8fmq9fD4iAOgSIv4+XwWKUY2m6k7addG05dEVWNxXdGTXaIEHJskrhZtnAON/s8zWfPQbef+Ug19YBjaYKnKtB4hK8msHRf+a4h6cJpoU4w6KLwB49nvx97TFugJiKBAhIeEMcCVCVCW9uov7yhoqbsuhpWXff2CR+BuP3yr6nQHy5qyo7yxzO5n+Jg+/KUb9GfLElAlae9Gf7doB8d5IjRPD3Os1BP5xCKjnJn/OghzzwBi1VCjU6PV6+Pv7IyIiAiEhIQBEpSUiIgJTpkyx+ZjAwEBERERg+vTp5tt27NiBwMBA8zr79OmDmBh5u+zFixfh4yPK8/7+/rC3t0dERARGjhTt1DExMYiLizOvp8br+rSYl8XRDWg7UNzWRIQaFOag/sYXxW3NemLPS08DH4oqQR//Ptj9sKU/ypiHOkNqth7Ggjx06hiMTgAGdmoKoBOGWj+fsS+Qs08M9fMbDc2JVZYPLk9f8d1qOGxP3+6Ao71VB0vL2YLWpx8aN3AAnvwCaNEbmu7P2dxFJ70dHvNrDfjNwUOZeWjopIdOKz5MpgBAYV+s33UEpw/loIOzAy4mZiIKln43aZIT3tVOxirpLQRoLZ2AI41d0bi+A3INDnCEvPnNqYUvNjwxEFdPh8E9UgQso8YOWsnSY1/bwB0HZgyCc2EKsNgysqO95joudVgGQ/JF8wHQpJG7J4Y2a4lbmR441fxztDg3C2s1gxHs2xkwzc+ldYB977G4fX4XGueXLD236D8OTRP3AZfloaaeRjTjXZea4FZmPoB8pDo+jB9xEaM1v+Mt+zUYoduP9tq/YAcD/Byz8HKumDsox8EdCRpX9C4QH/77NT3xIooqPw4uKMwEDmR6wFvXGLAKiwXuXdDX72lgz//QQlN2s5W3VpyFXTV6oJXWckKSVL89Cg0OsDOWnCH6V6kfpkqb0E4jmkh2GXsiy74xYBRn/IXQwg7ig9NBUwB/jWiey7JzQ/3CVCQ6d0WLhp44H58OvZ0OW/AQhmE/4qSmuKDriLV2Q/GcnzfeeDwI57f+CbvbFzF90GjcyZUwsGMTceJgZUTPZsCH4hIdeQ7u6O/THLgkWwS33boDRcUG1/wEROT2wgj5atCgUF49yS804sfzBRjpALgmHcGzn32PKXaX8KQOCLvUHLHtQnHklxRk55+D3k6L+b4dSgSl3zZ8jwsNLmFG0jlkal3wQ8N/4rW4pwFDHg6s+wz79P3hefzfGK+TN39e/TMGt1O+gz+AJOeuaJpxVlSzbJC8/GDoEgK7+GhRUZEkGNeNg/aC1YEz5QqwyBfo9AQKkq+It0vbR0UlyFgAfNUPma2CYePKdvIKEwD8OArQ6ZHXehAcMuIBB1eg76uiP9TpdSI8DFsoDxwxW2Fc/xK0pikgEk+LL2uevqIpqO2jIsSc32S573/jRYWtaGTe7aifsNUwCH/76wjMh9W4SODcRkhdQpCWmgI3U/+yibuADZNKzCBtdGyII7kt0bPQAAePrjb/tnBrKapx1tu6bqztZQERLDOTRGXvp4nykJuRIEIHYKmatO4vmqZdmomKli06B3llpkhB12dgf9ZqGgFDnphfp+UDQLe/IffCdss5WbSN6Ra6jxL9H29fRq6nPxIjFsPn0nco3PUx7DoMQdqh7+FamAtkxCNr27tIfvgjtLq1B9j3KQx+zyN73xLc7vkPtApSb6JGjSRVbPzl2rVrMW7cOPznP/9B3759sWjRIqxbtw4XLlyAh4cHxo4di+bNmyMsLAyAGNI9YMAAzJ8/H8OGDUN4eDg+/vhjHD9+HN26dQMAbNiwAaNGjcKSJUswcOBAbNu2DdOnT8eePXvw0EMPAQBee+01bN26FStXroSLiwumTp1qXn95pKenw9XVFWlpaXBxcbn7A6pDRoJIvvUbi9/jDokyqfWFDZ9fD3R4XIxaurAFeOpLcWXsyjAUirMQe0fRae/SdqCBB/Cm1T9ywmlxVub/ojibyc8GtswUo6Ts6wEBrwKD3in1Kaoi7nY2nO0lOP83AMa8LFx5fAXa9eiPzF0L0fCA5azn+pQb8HZ3Fn+PG0fF2UTMVlG+DpwiwiEgLg1x+xLQ+yXg1+nmyhg8fUX/nYJc4COPkhsCiLO8flOBA6KqgAk7Ae8+tpf9T3/RNDDuVzHSZluo5azJvaOl38SUY2IY9hc9ba5mV/BO5Du3QExCJsb184GzXovkPUvhcfRTaEq7dMFDM8UZ8bqxkDRa5M78E/UWtAIASMMWIr7987idmY/GNyPQbOt4y+NGfitK6p+1t/TF0dqbDwgFj32MwjaDUO8/AeaHpA38CK67xay4koMLMOsyNB9aNY2O+xXGNaNR0PVvMAxdALs7V6BfNRzIiEfusz/CIfkMNLs/Esu+Hi36Q2XcFJ2BL20XB5RH54qz9+b+gGtzmD+OslNQEHcU9h2CoNFV6NzL4t2iprmASaKT57ePiYOFKdzPiYdh6z+hi/4Bl4aswXXJA49uG1TmKrMdPfGy/XysyXhR/N0kHW7DBZ6aO5hV8ArWGx6RLe+IPFxwFK/DPoMv+utOI0tywE6jP4brDmJN4aOYUzgBlxzGwl4jQoyp6lhcnLEJdBojmmtuY3L+6xhrt10W/k0KJB1eKAhFO81f+NB+BS47dMG32pEIy/kA+ZIdPnWYDNfsq5hi90uJx4a1XYUh1z5Bj0L5rLS5kj0cNeK9kqhvCY/8sjuiXvYYgk3t3odTygVMOv9CifvzJR30GtsjPW/W6wCNnSOckYnUsREIP56MhDN78VlGKZfQKEWicxd4ZIimxLN2XdGoIB5emhTkuLbFog6r8OhfSxFw8wfZYzYZAvF6wVT0aumGNx/viG1nE2AwSni0U1PkFRoRde0O7HVaBF1biN4Ja209rdk5qRUKJQ26a2NxqFEI/O78jnpSDgrs6kOrs4cuL1X8LZ7+FnGn96Pd5RUwQItfH/kN+5Pr4aV+rdC58BxSLuxD40jRPLS3ywcoSLqIVXZ/Q8Prv2OgZx76eOrgdVZcFucf2new1Pg+ACC96wtwOfuDzW2zZoAWOhhxQ2qCt31Ww7meHtduZyEmIQNOhanY5fAmGmoycdCxP/rl7pM9dn1hfwyzOwInWKYbiLdrDq/Z0WIAjUIqcvyucKgBgMWLF+PTTz9FQkICevTogS+++AIBAeLD8JFHHkGrVq2wcuVK8/Lr16/H22+/jatXr6J9+/b45JNPMHSorK6A5cuXIywsDDdu3EDHjh3x3nvvYfhwS0e43NxcvPHGG/jxxx+Rl5eH4OBgLF26tNTmp+JqRKgpzfnNwNoxYgj0CxuVu7Cdtd/fEp3v2g4CXvj57svnZYjRQ/eilFiQI8qf+qJhtZIkRtKcXicqXM+srPg6f34FOFX0odN6ADCu6AzPdKCz1uYRUVL28BUdCAFg6nHRtm5LYb7o02IaIp4aJ+bUKMgGAl4TE+pJkqVT8ZXdou3eqztwrGjqA40OeDsJsHXAPvwfMdS9uE5PiJK+UyNgxVARBJ76QkzkF7sPeHgmoC0asfVXlLi+kck/DonRaNZ/lxZ9LGfOr+wRzRWf+4mDvqevGEX3eXcxUeSz3wPtH7P8/Vy9gRlnRD8G6wu6ZiaLM9i2j4q/y5rngL4Tgd5WAeteubpfnBw8/oF4b92+IvrD7PpQlM8HzBJNMpmJlpFUty6LvhsevpYRT9Y0WmDeHdEf5cDnsuaUqKB1WHK5EQZ388RQXy+8sS4aGbmFmKtdgbZ39uP8Ez+jzbZxcE619PPY4bcIB3R98e5xG3M6AThubI872kYYBMucTFma+pjb7mc8kLEdzyYsQL6kw1rDQBigxQeFL8AehciFA0Zo92GhXt4v8YfCIMwtfAlaGNFHE4M22psIs7d0nO6YuxJNNKkI0FzAeLtt6Ka9CgD4oODvmGsvzuyfyPsQmx3EqLKLxubw1KTgv4XD0EF7HU/oxHZOyp+ObUbRX26p/SIM1cn7aT2d9x4aaHLwg34+AHloGpb3Ec5JPpCggXU76TO6PZhv9w1+kR7CWUNLDNEdRbLkinkFL2KXwxtooJHP49M/799Yr38PHppU2e1vFbyE1YYg+Gti8JPDewBEldhVk41pBZPxi+FB3I23JhE/6d+DGzJKhLMvC0NgBwNWFQbhOft9mKqzVL0jDV3wWsE0pMIZK+z/DwN18hmsFxWOwKLCvwEQhwFHOx3aFV7Cr0V/71a5a0psy1PaA/hCvwQA0Db3BzymjYKv9k8sKvwb3rJbhRfttqNQ0pqbx29JLrgpNUZ3bSyijO0RbhiIT+2/xueFT+Pfhc/I1t3crR6e1O7HP7MWQqsRUSFH0uNbwxD8Q7fJfJvJcU0XnAhYhJeC+0Kj4HGs2kPN/ahGhxpAjJxxaWY5sCst4bQokT72vmgbremMBjG0trm/pbJVEWd+EqMIADG89umiD/cPmsgnHLR3At6KtzznJ61FReefV+QXOlRC1m3g+6dEfwDfZ4BhC2wvZygEtswQ7fkOzmJEUcgywKWU4eS25GcBi/uIUV1ePcQEdTo70XFy6ywR9Ho8D/y7qC/b3Nvi/u1zRVPBYx8AD74uRt84NbaMPjsZLjpIPvsD0LRTlf4cNd4XvUQTTYu+lkn6rN8vd66K/hyGPNHUMrQcE63F/CaaA0zm3BT/86aw6OAqLr4afxJo8wjSnvkfHDQGOM63qjD6vwg8+bl4jTdNheQdgC8zH0VCei6mDGwHg1FCPb0OUsw2NPnV0iwi6fTYF7wNZ7JcEdzVAwev3EZadgEC8w6g1/HZuG7fGmHNFuPpXs2ht9PCPv0G2lz8L1z6/h3/Pt8A46/NRq69G9b7zEWXK9/ioVvrsOuBFRjySH/E3spGxMFITLkwFgUaB/yj6Q/wcG8EoyThemwMQjXfoU32STQwimar9DeuIyVPB5e087A7+xN0PUYh4+cZOOcVguhGQxCfmoPdMcm4nZWHnt5uCGjTGGsOx0Gfk4Q7cIafTxN8GNINWXmF2B2ThB7nPsFjafIOtpPa7kJw81x4pEbjRnoBHBu3xH9OG5FodMMDbRrB1VGL1y+9hAbIxvmg71Dv9ln49H8BMYkZCP35NFKyCtDbpyEa1tfj2NUU5BuMGNChCex1WhQYjLh2Oxs3L53ADgdxAnLEIRCt7W7jDYd5GPFwT/Rs6QbPzPNwWCGqf0lNAvFT+//DxrNpuJmWg4dwAl8hDDmSHukaZ2Q06oqphdNx8ZbY52PXRNOno70Wo51PISqtAWLt2uG5vt6w02nxYFt3rDt2HdvP3MBH9dcjIrcjrjbuj4GdmuDn438hOSMPvZs7YLzzETi1748mh8Lg2MANzZ6YjdMpdshKioW2eW+k5xXCxy4FUgMvbD+fDK1Wg67NXOHT2AntmzaAJAFnj+2G29FFaJp3DbEtR+Byh4kYYB+D+lsmQZuZgLig/yDDtR3adewOB71yFRoThhobanyoIeUlx4gzat9nLFWX9JuiGeT2JTHXx4hvLB31gKKhkrmiDfp+ZygQ1SMHl9Krf9ePiOBkmlOoME/0Q2jVH9CqPjhSXSmx4v3i0090lNz0OjDsM1GFMon5TZwwPDQD0NmXvi5rx5aLWXu7jQRGFs1ntHmG6Cg7fqu4nlXUCqDjMMC9qHL4ZW/LNAGvRcqHHJemIFd0FvXqIaqu9RoCLfxtL5ubJuZhqmqTQfJFUS20VeXMzxKVQo+uwMA5d11VocGIfIMRTno78++XkjLhUs8ezVwd5ZWA3DTRPO0dgKxf3oTU5Sk0eKAc1cGCXABSpSvSJ+PuoF3kP1HfXguEfFXyf0aSxGugbyCaxU2VVNM+JsYgTdcQrg3dYafTotBgRHpuIRrV1+NWZh7Scgrg3dAJejstUrPzodFo4FrP9vus0GCERqOBTquBJEkwSjD3aaw2eRliKHs1n+Aw1NjAUENENUZmsggZpuZHSRJhurSDa/xJ0dTVYQjgXEq/MKJaqiLH70r2wCMiokozXcTURKMpu1rg5Se+iKhMdby+TERERLUFQw0RERHVCgw1REREVCsw1BAREVGtwFBDREREtQJDDREREdUKDDVERERUKzDUEBERUa3AUENERES1AkMNERER1QoMNURERFQrMNQQERFRrcBQQ0RERLVCnblKtyRJAMQlzImIiOj+YDpum47jZakzoSYjIwMA4O3trfKWEBERUUVlZGTA1dW1zGU0UnmiTy1gNBpx8+ZNODs7Q6PRKLru9PR0eHt74/r163BxcVF03TVBbd8/oPbvY23fP6D272Nt3z+g9u9jbd8/oHr2UZIkZGRkoFmzZtBqy+41U2cqNVqtFi1atKjW53Bxcam1b1Sg9u8fUPv3sbbvH1D797G27x9Q+/extu8foPw+3q1CY8KOwkRERFQrMNQQERFRrcBQowAHBwfMmzcPDg4Oam9Ktajt+wfU/n2s7fsH1P59rO37B9T+fazt+weov491pqMwERER1W6s1BAREVGtwFBDREREtQJDDREREdUKDDVERERUKzDUVNGSJUvQqlUrODo6IiAgAEeOHFF7kyrt3XffhUajkX116tTJfH9ubi4mT56Mxo0bo0GDBhg5ciQSExNV3OKy7du3D08++SSaNWsGjUaDjRs3yu6XJAnvvPMOvLy8UK9ePQQFBeHSpUuyZVJSUjBmzBi4uLjAzc0NEyZMQGZm5j3ci7LdbR9ffPHFEq/p4MGDZcvU5H0MCwtDnz594OzsjKZNmyIkJAQxMTGyZcrzvoyLi8OwYcPg5OSEpk2bYtasWSgsLLyXu2JTefbvkUceKfEaTpo0SbZMTd0/APjqq6/QvXt382RsgYGB+O2338z338+vH3D3/bvfX7/i5s+fD41Gg+nTp5tvq1GvoUSVFh4eLun1emn58uXS2bNnpYkTJ0pubm5SYmKi2ptWKfPmzZO6du0qxcfHm7+Sk5PN90+aNEny9vaWIiIipGPHjkkPPPCA1K9fPxW3uGxbt26V3nrrLennn3+WAEgbNmyQ3T9//nzJ1dVV2rhxo3Ty5Enpqaeeklq3bi3l5OSYlxk8eLDk5+cnHTp0SPrjjz+kdu3aSaNHj77He1K6u+3juHHjpMGDB8te05SUFNkyNXkfg4ODpRUrVkhnzpyRoqOjpaFDh0otW7aUMjMzzcvc7X1ZWFgodevWTQoKCpJOnDghbd26VXJ3d5dCQ0PV2CWZ8uzfgAEDpIkTJ8pew7S0NPP9NXn/JEmSNm3aJG3ZskW6ePGiFBMTI82ZM0eyt7eXzpw5I0nS/f36SdLd9+9+f/2sHTlyRGrVqpXUvXt3adq0aebba9JryFBTBX379pUmT55s/t1gMEjNmjWTwsLCVNyqyps3b57k5+dn877U1FTJ3t5eWr9+vfm28+fPSwCkyMjIe7SFlVf8gG80GiVPT0/p008/Nd+WmpoqOTg4SD/++KMkSZJ07tw5CYB09OhR8zK//fabpNFopL/++uuebXt5lRZqhg8fXupj7rd9TEpKkgBIe/fulSSpfO/LrVu3SlqtVkpISDAv89VXX0kuLi5SXl7evd2Buyi+f5IkDorWB5Di7qf9M2nYsKH03//+t9a9fiam/ZOk2vP6ZWRkSO3bt5d27Ngh26ea9hqy+amS8vPzERUVhaCgIPNtWq0WQUFBiIyMVHHLqubSpUto1qwZ2rRpgzFjxiAuLg4AEBUVhYKCAtn+durUCS1btrwv9zc2NhYJCQmy/XF1dUVAQIB5fyIjI+Hm5obevXublwkKCoJWq8Xhw4fv+TZX1p49e9C0aVN07NgRr732Gm7fvm2+737bx7S0NABAo0aNAJTvfRkZGQlfX194eHiYlwkODkZ6ejrOnj17D7f+7orvn8nq1avh7u6Obt26ITQ0FNnZ2eb77qf9MxgMCA8PR1ZWFgIDA2vd61d8/0xqw+s3efJkDBs2TPZaATXvf7DOXNBSabdu3YLBYJC9SADg4eGBCxcuqLRVVRMQEICVK1eiY8eOiI+Px3vvvYeHH34YZ86cQUJCAvR6Pdzc3GSP8fDwQEJCgjobXAWmbbb1+pnuS0hIQNOmTWX329nZoVGjRvfNPg8ePBgjRoxA69atceXKFcyZMwdDhgxBZGQkdDrdfbWPRqMR06dPx4MPPohu3boBQLnelwkJCTZfZ9N9NYWt/QOA559/Hj4+PmjWrBlOnTqFf/3rX4iJicHPP/8M4P7Yv9OnTyMwMBC5ublo0KABNmzYgC5duiA6OrpWvH6l7R9QO16/8PBwHD9+HEePHi1xX037H2SoIbMhQ4aYf+7evTsCAgLg4+ODdevWoV69eipuGVXWc889Z/7Z19cX3bt3R9u2bbFnzx4MGjRIxS2ruMmTJ+PMmTPYv3+/2ptSLUrbv1deecX8s6+vL7y8vDBo0CBcuXIFbdu2vdebWSkdO3ZEdHQ00tLS8L///Q/jxo3D3r171d4sxZS2f126dLnvX7/r169j2rRp2LFjBxwdHdXenLti81Mlubu7Q6fTlejhnZiYCE9PT5W2Sllubm7o0KEDLl++DE9PT+Tn5yM1NVW2zP26v6ZtLuv18/T0RFJSkuz+wsJCpKSk3Jf7DABt2rSBu7s7Ll++DOD+2ccpU6Zg8+bN2L17N1q0aGG+vTzvS09PT5uvs+m+mqC0/bMlICAAAGSvYU3fP71ej3bt2sHf3x9hYWHw8/PD559/Xmtev9L2z5b77fWLiopCUlISevXqBTs7O9jZ2WHv3r344osvYGdnBw8Pjxr1GjLUVJJer4e/vz8iIiLMtxmNRkRERMjaUu9nmZmZuHLlCry8vODv7w97e3vZ/sbExCAuLu6+3N/WrVvD09NTtj/p6ek4fPiweX8CAwORmpqKqKgo8zK7du2C0Wg0fzDdb27cuIHbt2/Dy8sLQM3fR0mSMGXKFGzYsAG7du1C69atZfeX530ZGBiI06dPy8Lbjh074OLiYm4iUMvd9s+W6OhoAJC9hjV1/0pjNBqRl5d3379+pTHtny332+s3aNAgnD59GtHR0eav3r17Y8yYMeafa9RrqGi34zomPDxccnBwkFauXCmdO3dOeuWVVyQ3NzdZD+/7yRtvvCHt2bNHio2NlQ4cOCAFBQVJ7u7uUlJSkiRJYthey5YtpV27dknHjh2TAgMDpcDAQJW3unQZGRnSiRMnpBMnTkgApIULF0onTpyQrl27JkmSGNLt5uYm/fLLL9KpU6ek4cOH2xzS3bNnT+nw4cPS/v37pfbt29eY4c6SVPY+ZmRkSG+++aYUGRkpxcbGSjt37pR69eoltW/fXsrNzTWvoybv42uvvSa5urpKe/bskQ2Jzc7ONi9zt/elaTjp448/LkVHR0vbtm2TmjRpUiOGzN5t/y5fviy9//770rFjx6TY2Fjpl19+kdq0aSP179/fvI6avH+SJEmzZ8+W9u7dK8XGxkqnTp2SZs+eLWk0Gmn79u2SJN3fr58klb1/teH1s6X4iK6a9Boy1FTRl19+KbVs2VLS6/VS3759pUOHDqm9SZU2atQoycvLS9Lr9VLz5s2lUaNGSZcvXzbfn5OTI/3jH/+QGjZsKDk5OUlPP/20FB8fr+IWl2337t0SgBJf48aNkyRJDOueO3eu5OHhITk4OEiDBg2SYmJiZOu4ffu2NHr0aKlBgwaSi4uLNH78eCkjI0OFvbGtrH3Mzs6WHn/8calJkyaSvb295OPjI02cOLFE6K7J+2hr3wBIK1asMC9Tnvfl1atXpSFDhkj16tWT3N3dpTfeeEMqKCi4x3tT0t32Ly4uTurfv7/UqFEjycHBQWrXrp00a9Ys2TwnklRz90+SJOmll16SfHx8JL1eLzVp0kQaNGiQOdBI0v39+klS2ftXG14/W4qHmpr0GmokSZKUrf0QERER3XvsU0NERES1AkMNERER1QoMNURERFQrMNQQERFRrcBQQ0RERLUCQw0RERHVCgw1REREVCsw1BAREVGtwFBDREREtQJDDREREdUKDDVERERUKzDUEBERUa3w/2KCu9pi/2UPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  Training metrics\n",
    "loss_df = pd.DataFrame(model_1.history.history)\n",
    "loss_df.plot()\n",
    "\n",
    "# the validation loss stays close to the training loss \n",
    "# without large gaps indicates \n",
    "# that the model is not overfitting\n",
    "\n",
    "# Both the training and validation loss values are low, \n",
    "# which suggests the model is learning effectively \n",
    "# and minimizing errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "0.06003595516085625\n",
      "\n",
      "Train data evaluation:\n",
      "0.05942883342504501\n"
     ]
    }
   ],
   "source": [
    " # compare test error values to training error values\n",
    "# the model is often good when these error values are similar\n",
    "# even if you training metrics above didn't overlap\n",
    "# you might still get very close values in evaluation => more important\n",
    "\n",
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model_1.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model_1.evaluate(X_train, y_train, verbose=0))\n",
    "\n",
    "# The train loss (0.0589) and test loss (0.0595) are very close\n",
    "# this is a good sign :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m936/936\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 59868 into shape (29934,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m model_1\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# reshape the data for easier comparison table\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mtest_predictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(np\u001b[38;5;241m.\u001b[39masarray(y_test), columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest True Y\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      6\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pred_df, test_predictions], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 59868 into shape (29934,)"
     ]
    }
   ],
   "source": [
    "test_predictions = model_1.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# these values follow a linear line = good predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# we basically compare the predicted values \u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# to true test values and see the differences\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest True Y\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel Predictions\u001b[39m\u001b[38;5;124m'\u001b[39m, data\u001b[38;5;241m=\u001b[39m\u001b[43mpred_df\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_df' is not defined"
     ]
    }
   ],
   "source": [
    " # these values follow a linear line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Regression error metrics\n",
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"$\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"$^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"$\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>Race</th>\n",
       "      <th>Diabetic</th>\n",
       "      <th>PhysicalActivity</th>\n",
       "      <th>GenHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>KidneyDisease</th>\n",
       "      <th>SkinCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>24.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>31.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>28.37</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>28.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeartDisease    BMI  Smoking  AlcoholDrinking  Stroke  PhysicalHealth  \\\n",
       "0             0  20.34        0                0       1               0   \n",
       "1             0  24.21        0                0       0               0   \n",
       "2             0  31.64        1                0       0               5   \n",
       "3             0  28.37        1                0       0               0   \n",
       "4             0  28.15        0                0       0               7   \n",
       "\n",
       "   MentalHealth  DiffWalking  Sex  AgeCategory  Race  Diabetic  \\\n",
       "0             0            0    0           80     0         0   \n",
       "1             0            0    0           77     0         0   \n",
       "2             0            1    0           80     0         2   \n",
       "3             0            1    1           77     0         2   \n",
       "4             0            1    0           80     0         0   \n",
       "\n",
       "   PhysicalActivity  GenHealth  SleepTime  Asthma  KidneyDisease  SkinCancer  \n",
       "0                 1          3          7       0              0           0  \n",
       "1                 0          2          6       0              0           1  \n",
       "2                 0          2          9       1              0           0  \n",
       "3                 1          3          8       0              0           0  \n",
       "4                 0          2          7       0              0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload data\n",
    "df = pd.read_csv(\"balanced_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HeartDisease', 'BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
       "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
       "       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
       "       'Asthma', 'KidneyDisease', 'SkinCancer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the column names for easier copying for X/y\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  X/y -variables\n",
    "\n",
    "# if you  have more than one independent variables, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "# in this case, everything else except the amount_paid\n",
    "X = df[['BMI', 'Smoking', 'AlcoholDrinking', 'Stroke',\n",
    "       'PhysicalHealth', 'MentalHealth', 'DiffWalking', 'Sex', 'AgeCategory',\n",
    "       'Race', 'Diabetic', 'PhysicalActivity', 'GenHealth', 'SleepTime',\n",
    "       'Asthma', 'KidneyDisease', 'SkinCancer']]\n",
    "\n",
    "# have only the target variable here (dependent variable)\n",
    "# in this case, amount_paid => how big is the electricity bill\n",
    "y = df['HeartDisease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Train/test/validation -split\n",
    "\n",
    "# unfortunately the scikit-learn's train_test_split doesn't support validation\n",
    "# set split in itself.\n",
    "# if you want to split the test set into two for a validation set too, try this trick:\n",
    "\n",
    "# first, train/test split => 70% for training, 30% for other purposes (temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# now, split the 30% for other purposes by 50% (resulting in 2 x 15%)\n",
    "# so finally, we have:\n",
    "# 70% for training\n",
    "# 15% for testing\n",
    "# 15% for validation\n",
    "# => 70 + 15 +15 = 100%\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data amount: 139688\n",
      "Test data amount: 29934\n",
      "Validation data amount: 29933\n"
     ]
    }
   ],
   "source": [
    "# just seeing how much data we have in each\n",
    "print(f\"Train data amount: {len(X_train)}\")\n",
    "print(f\"Test data amount: {len(X_test)}\")\n",
    "print(f\"Validation data amount: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e1003118\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.activations' has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m variable_amount \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define Sequential neural network model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# I have 18 columns --> 18 - 1 = 17 input layers\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# I have 2 options for output (Yes or No for Heart disease)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# but it started to show an error\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# ValueError: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 2)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     13\u001b[0m     [\n\u001b[1;32m---> 14\u001b[0m         \u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvariable_amount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     15\u001b[0m         layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m32\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     16\u001b[0m         layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m     17\u001b[0m         layers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Use 1 neuron with sigmoid for binary classification\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     ]\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# CHANGED loss='mse' --> loss='categorical_crossentropy',\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# ADDED metrics=['accuracy']\u001b[39;00m\n\u001b[0;32m     23\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\core\\dense.py:89\u001b[0m, in \u001b[0;36mDense.__init__\u001b[1;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, lora_rank, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(activity_regularizer\u001b[38;5;241m=\u001b[39mactivity_regularizer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;241m=\u001b[39m units\n\u001b[1;32m---> 89\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation \u001b[38;5;241m=\u001b[39m \u001b[43mactivations\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(activation)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_bias \u001b[38;5;241m=\u001b[39m use_bias\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkernel_initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(kernel_initializer)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.src.activations' has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "#  Create neural network structure\n",
    "variable_amount = len(X.columns)\n",
    "\n",
    "# Define Sequential neural network model\n",
    "# I have 18 columns --> 18 - 1 = 17 input layers\n",
    "# I have 2 options for output (Yes or No for Heart disease)\n",
    "# --> 2 output layers\n",
    "\n",
    "# WANTED TO ADD activation=\"softmax\" to the last layer\n",
    "# but it started to show an error\n",
    "# ValueError: Arguments `target` and `output` must have the same shape. Received: target.shape=(None, 1), output.shape=(None, 2)\n",
    "model_2 = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(7, activation=\"relu\", input_shape=(variable_amount,)),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        layers.Dense(16, activation=\"relu\"),\n",
    "        layers.Dense(1, activation=\"sigmoid\")  # Use 1 neuron with sigmoid for binary classification\n",
    "    ]\n",
    ")\n",
    "\n",
    "# CHANGED loss='mse' --> loss='categorical_crossentropy',\n",
    "# ADDED metrics=['accuracy']\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e1003118\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\losses\\losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 938us/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 2/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 985us/step - accuracy: 0.9252 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 3/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 4/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 5/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 6/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 7/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 8/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 9/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 10/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 11/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 12/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 13/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 14/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 15/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 16/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 17/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 18/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 19/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 20/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 21/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 22/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 23/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 24/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 25/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 26/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 27/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 28/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 29/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 30/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 31/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 32/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 33/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 34/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 35/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 36/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 37/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 38/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 39/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9249 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 40/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 41/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 42/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 43/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 44/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 45/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 46/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 47/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 48/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 49/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 50/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 51/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 52/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 53/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 54/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 55/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 56/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 57/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 58/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 59/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 60/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 61/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 62/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 63/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 64/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9255 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 65/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 66/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 67/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 68/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 69/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 70/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 71/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 925us/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 72/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 880us/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 73/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 935us/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 74/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 75/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 76/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 953us/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 77/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 78/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 905us/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 79/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 80/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 81/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 952us/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 82/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 862us/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 83/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 950us/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 84/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 85/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 86/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 87/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 88/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 89/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 90/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 91/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 92/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 923us/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 93/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 869us/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 94/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 888us/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 95/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 906us/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 96/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 882us/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 97/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 854us/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 98/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 906us/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 99/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 985us/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 100/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 101/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 949us/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 102/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 103/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 997us/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 104/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 105/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 106/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 929us/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 107/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 968us/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 108/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 984us/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 109/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 110/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 111/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 112/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 113/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 114/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 115/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 116/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 117/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 118/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 119/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9277 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 120/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 121/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 122/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 123/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 124/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 909us/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 125/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 880us/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 126/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 895us/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 127/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 938us/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 128/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 947us/step - accuracy: 0.9249 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 129/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 130/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 131/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 955us/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 132/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 939us/step - accuracy: 0.9254 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 133/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 972us/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 134/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 891us/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 135/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 136/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 137/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 138/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 139/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 140/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 141/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 142/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 7ms/step - accuracy: 0.9253 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 143/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 144/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 145/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 7ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 146/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - accuracy: 0.9254 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 147/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 148/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 149/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 150/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9252 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 151/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 152/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 153/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 154/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 155/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 7ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 156/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.9278 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 157/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9275 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 158/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.9254 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 159/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 160/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 161/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 7ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 162/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 163/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 164/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 165/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 166/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 167/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 168/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 169/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 170/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 171/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 172/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 173/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 174/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 175/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 176/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 177/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 178/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 179/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 180/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 181/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 182/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 183/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 184/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 185/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 186/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 187/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 188/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 189/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 190/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 191/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 192/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 193/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 194/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 195/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 196/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 197/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 198/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 199/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 200/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 201/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 202/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 203/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 204/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 205/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 206/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 207/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 208/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 209/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 210/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 211/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 212/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 213/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 214/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 215/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 216/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 217/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 218/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 219/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 220/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 221/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9246 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 222/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 223/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 224/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 225/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 226/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 227/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 228/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 229/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 230/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 231/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 232/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 233/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 234/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 235/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9250 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 236/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 237/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 238/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 239/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 240/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 241/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 242/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 243/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 244/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 245/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 246/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 247/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 248/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 249/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 250/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 251/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 252/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 253/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 254/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 255/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 256/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 257/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 258/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 259/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 260/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 261/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 262/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 263/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 264/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 265/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 266/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 267/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 268/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 269/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 270/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 271/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 272/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 273/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 274/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 275/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 276/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 277/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 278/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 279/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 280/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 281/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 282/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 283/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 284/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 285/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 286/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 287/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 288/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 289/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 290/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 291/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 292/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 293/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9252 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 294/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 295/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 296/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 297/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 298/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 299/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 300/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 301/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 302/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 303/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 304/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 305/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 306/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9252 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 307/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 308/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 309/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 310/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 311/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9274 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 312/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 313/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 314/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 315/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 8ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 316/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 317/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.9282 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 318/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 11ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 319/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 320/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 7ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 321/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 322/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 323/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 324/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 5ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 325/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 8ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 326/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 8ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 327/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 328/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 6ms/step - accuracy: 0.9258 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 329/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 330/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 331/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9281 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 332/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 8ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 333/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 9ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 334/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 8ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 335/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 9ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 336/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 9ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 337/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 7ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 338/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9266 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 339/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 340/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 341/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 342/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 5ms/step - accuracy: 0.9279 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 343/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 344/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 345/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 346/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 347/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 348/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 6ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 349/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 350/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 7ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 351/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 352/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 6ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 353/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 6ms/step - accuracy: 0.9256 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 354/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 8ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 355/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 6ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 356/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 357/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 358/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 359/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 360/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 361/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 362/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 363/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 364/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 365/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 366/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 367/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 368/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9276 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 369/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 370/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 371/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.9265 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 372/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3ms/step - accuracy: 0.9251 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 373/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 3ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 374/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 375/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.9269 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 376/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 377/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9267 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 378/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 379/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9255 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 380/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 381/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 382/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9280 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 383/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 384/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 385/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 386/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 387/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.9263 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 388/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 3ms/step - accuracy: 0.9248 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 389/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 390/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9261 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 391/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 4ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 392/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 393/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.9268 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 394/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 4ms/step - accuracy: 0.9260 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 395/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 396/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 397/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 5ms/step - accuracy: 0.9259 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 398/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 399/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 4ms/step - accuracy: 0.9273 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n",
      "Epoch 400/400\n",
      "\u001b[1m4366/4366\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.0000e+00 - val_accuracy: 0.9257 - val_loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2145d01dbb0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Train the neural network with our data\n",
    "\n",
    " # using validation again for better metrics and optimization\n",
    "model.fit(x=X_train, y=y_train, epochs=400, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame(model\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mhistory)\n\u001b[0;32m      2\u001b[0m loss_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    " loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df[['loss', 'val_loss']].plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df[['accuracy', 'val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # compare the final model loss/accuracy/evaluation values\n",
    "# the values should again match mostly\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions and convert with argmax() to get categories \n",
    "# instead of raw probabilities\n",
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = np.argmax(test_predictions, axis=1)\n",
    "\n",
    "# convert also y-test -values with argmax\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, test_predictions), xticklabels=categories, yticklabels=categories, annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In multi category classification , AUC values are often interpreted as follows: \n",
    "# 0.5-0.6 (failed)\n",
    "# 0.6-0.7 (worthless)\n",
    "# 0.7-0.8 (poor)\n",
    "# 0.8-0.9 (good)\n",
    "# > 0.9 (excellent)\n",
    "\n",
    "# get ROC-AUC -score\n",
    "roc_auc_score(y, model.predict(X), multi_class=\"ovr\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
